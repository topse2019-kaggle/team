{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追加評価用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Driveのマウント\n",
    "任意のフォルダを指定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd \"drive/My Drive/pytorch/評価\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visdom接続用\n",
    "そのままで問題ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "! npm install -g localtunnel\n",
    "!python3 -m pip install visdom\n",
    "!python3 -m visdom.server -port 8097 >> visdomlog.txt 2>&1 &\n",
    "!lt --port 8076 >> url.txt 2>&1 &\n",
    "\n",
    "import time\n",
    "time.sleep(5)\n",
    "! cat url.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各種ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import utils\n",
    "from lib import utils_transform as utils_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各種パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### クラス数\n",
    "class_size=2\n",
    "### ミニバッチサイズ\n",
    "batch_size=128\n",
    "### 各種データセットのファイルパス(学習用、評価用、テスト用)\n",
    "train_path=\"./data/find-a-car-park/data/train\"\n",
    "val_path=\"./data/find-a-car-park/data/val\"\n",
    "test_path=\"./data/find-a-car-park/data/test\"\n",
    "### 学習済みパラメータの保存先\n",
    "save_root=\"./test/find_a_car_park\"\n",
    "### epoch数\n",
    "epoch_count=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各種実行設定\n",
    "実行時間を考慮して、適宜コメントアウトしてください。<br>\n",
    "乱数シード * transoformの分だけループを繰り返します。<br>\n",
    "\n",
    "【イメージ】<br>\n",
    "random_seed_list=[0,1] <br>\n",
    "transform_list = [<br>\n",
    "    \"trainsform_none\",<br>\n",
    "    \"trainsform_horizontal_flip\"<br>\n",
    "]<br>\n",
    "\n",
    "シード0：transform_none、tronsform_horizontal_fripを実行<br>\n",
    "シード1：transform_none、tronsform_horizontal_fripを実行<br>\n",
    "\n",
    "<font color=\"Red\">\n",
    "※transform_noneは、Data Augmentationなし。transform_allは全Data Augmentaionあり。<br>\n",
    "※基本的に、transform_〇〇を使用して、Data Augmentationの効果を測定します。<br>\n",
    "※exclude_〇〇は該当Data Augmentaionのみを除いた設定になります。<br>\n",
    "　効果の大きさを検証するもののため、こちらは時間があれば、実行するようにしてください。<br>\n",
    "</font>\n",
    "<br>\n",
    "<font color=\"Blue\">\n",
    "※Data Augmentationの設定を切り替える場合は、<br>\n",
    "transform_list=transform_listを変更してください。\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 乱数シードの設定\n",
    "random_seed_list=[\n",
    "    0,\n",
    "    1,\n",
    "    19,\n",
    "    53,\n",
    "    109,\n",
    "    537,\n",
    "    1732,\n",
    "    5196,\n",
    "    10005,\n",
    "    50704\n",
    "]\n",
    "\n",
    "### transfrom一覧(対象Data Autmentationのみ)\n",
    "transform_list = [\n",
    "    \"trainsform_none\",\n",
    "    \"trainsform_horizontal_flip\",\n",
    "    \"trainsform_vertical_flip\",\n",
    "    \"trainsform_rotation\",\n",
    "    \"trainsform_perspective\",\n",
    "    \"trainsform_crop\",\n",
    "    \"trainsform_erasing\"\n",
    "]\n",
    "\n",
    "### transform一覧(対象Data Augmentationを除く)\n",
    "transform_list_exclude = [\n",
    "    \"trainsform_all\",\n",
    "    \"exclude_horizontal_flip\",\n",
    "    \"exclude_vertical_flip\",\n",
    "    \"exclude_rotation\",\n",
    "    \"exclude_perspective\",\n",
    "    \"exclude_random_crop\",\n",
    "    \"exclude_random_erasing\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理を開始。2020-04-04 14:31:43.395407\n",
      "乱数シード=0\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 14:31:45.499411\n",
      "val Loss: 3.7175 Acc: 0.3267\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 14:31:56.453302\n",
      "train Loss: 0.7957 Acc: 0.6765\n",
      "val Loss: 0.7748 Acc: 0.6748\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 14:32:36.596534\n",
      "train Loss: 0.4860 Acc: 0.7961\n",
      "val Loss: 1.1867 Acc: 0.5015\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 14:33:16.777883\n",
      "train Loss: 0.4448 Acc: 0.8114\n",
      "val Loss: 0.5529 Acc: 0.7776\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 14:33:56.974515\n",
      "train Loss: 0.3430 Acc: 0.8636\n",
      "val Loss: 1.7664 Acc: 0.7193\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 14:34:37.183306\n",
      "train Loss: 0.3007 Acc: 0.8871\n",
      "val Loss: 1.2687 Acc: 0.8696\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 14:35:17.502602\n",
      "train Loss: 0.2323 Acc: 0.9116\n",
      "val Loss: 0.2716 Acc: 0.9080\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 14:35:57.723946\n",
      "train Loss: 0.1338 Acc: 0.9453\n",
      "val Loss: 0.2441 Acc: 0.9003\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 14:36:37.838569\n",
      "train Loss: 0.0951 Acc: 0.9627\n",
      "val Loss: 0.2935 Acc: 0.9018\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 14:37:17.978623\n",
      "train Loss: 0.0847 Acc: 0.9688\n",
      "val Loss: 0.3734 Acc: 0.8819\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 14:37:58.352742\n",
      "train Loss: 0.0707 Acc: 0.9775\n",
      "val Loss: 0.6814 Acc: 0.8604\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 14:38:38.629305\n",
      "train Loss: 0.0682 Acc: 0.9780\n",
      "val Loss: 0.1244 Acc: 0.9540\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 14:39:18.570544\n",
      "train Loss: 0.0932 Acc: 0.9653\n",
      "val Loss: 1.1307 Acc: 0.8405\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 14:39:58.728747\n",
      "train Loss: 0.0718 Acc: 0.9750\n",
      "val Loss: 0.1774 Acc: 0.9340\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 14:40:38.830012\n",
      "train Loss: 0.0539 Acc: 0.9831\n",
      "val Loss: 0.2934 Acc: 0.8865\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 14:41:19.042306\n",
      "train Loss: 0.0319 Acc: 0.9867\n",
      "val Loss: 0.2664 Acc: 0.9310\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 14:41:59.491812\n",
      "train Loss: 0.0327 Acc: 0.9898\n",
      "val Loss: 0.0935 Acc: 0.9663\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 14:42:39.735382\n",
      "train Loss: 0.0287 Acc: 0.9898\n",
      "val Loss: 0.0776 Acc: 0.9770\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 14:43:19.828580\n",
      "train Loss: 0.0358 Acc: 0.9877\n",
      "val Loss: 0.8901 Acc: 0.9110\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 14:43:59.995871\n",
      "train Loss: 0.0352 Acc: 0.9877\n",
      "val Loss: 0.0432 Acc: 0.9847\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 14:44:40.131406\n",
      "train Loss: 0.0247 Acc: 0.9903\n",
      "val Loss: 0.0249 Acc: 0.9908\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 14:45:20.404896\n",
      "train Loss: 0.0233 Acc: 0.9934\n",
      "val Loss: 0.2427 Acc: 0.9417\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 14:46:00.653512\n",
      "train Loss: 0.0617 Acc: 0.9785\n",
      "val Loss: 0.0833 Acc: 0.9739\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 14:46:41.075484\n",
      "train Loss: 0.0363 Acc: 0.9898\n",
      "val Loss: 0.0881 Acc: 0.9801\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 14:47:21.405717\n",
      "train Loss: 0.0103 Acc: 0.9985\n",
      "val Loss: 0.0202 Acc: 0.9939\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 14:48:01.608759\n",
      "train Loss: 0.0058 Acc: 0.9985\n",
      "val Loss: 0.0241 Acc: 0.9939\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 14:48:41.809260\n",
      "train Loss: 0.0056 Acc: 0.9980\n",
      "val Loss: 0.0503 Acc: 0.9801\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 14:49:22.179713\n",
      "train Loss: 0.0036 Acc: 0.9990\n",
      "val Loss: 0.0298 Acc: 0.9862\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 14:50:02.507030\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "val Loss: 0.0185 Acc: 0.9954\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 14:50:42.734377\n",
      "train Loss: 0.0007 Acc: 1.0000\n",
      "val Loss: 0.0159 Acc: 0.9969\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 14:51:23.150955\n",
      "train Loss: 0.0016 Acc: 0.9995\n",
      "val Loss: 0.0444 Acc: 0.9862\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 14:52:03.473005\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "val Loss: 0.0531 Acc: 0.9908\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 14:52:43.889122\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "val Loss: 0.0569 Acc: 0.9923\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 14:53:24.311478\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "val Loss: 0.0464 Acc: 0.9908\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 14:54:04.472847\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0450 Acc: 0.9923\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 14:54:44.771538\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0435 Acc: 0.9923\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 14:55:25.063914\n",
      "train Loss: 0.0006 Acc: 0.9995\n",
      "val Loss: 0.0347 Acc: 0.9923\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 14:56:05.397833\n",
      "train Loss: 0.0062 Acc: 0.9985\n",
      "val Loss: 0.0606 Acc: 0.9801\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 14:56:45.714735\n",
      "train Loss: 0.0317 Acc: 0.9888\n",
      "val Loss: 0.1425 Acc: 0.9494\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 14:57:26.035870\n",
      "train Loss: 0.0813 Acc: 0.9775\n",
      "val Loss: 0.4920 Acc: 0.8113\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 14:58:06.584849\n",
      "train Loss: 0.0533 Acc: 0.9801\n",
      "val Loss: 0.0829 Acc: 0.9785\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 14:58:46.807849\n",
      "train Loss: 0.0464 Acc: 0.9872\n",
      "val Loss: 0.0636 Acc: 0.9847\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 14:59:27.247669\n",
      "train Loss: 0.0207 Acc: 0.9954\n",
      "val Loss: 0.0412 Acc: 0.9816\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 15:00:07.756354\n",
      "train Loss: 0.0179 Acc: 0.9944\n",
      "val Loss: 0.1541 Acc: 0.9647\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 15:00:48.115505\n",
      "train Loss: 0.0182 Acc: 0.9939\n",
      "val Loss: 0.0397 Acc: 0.9893\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 15:01:28.641554\n",
      "train Loss: 0.0170 Acc: 0.9949\n",
      "val Loss: 0.1004 Acc: 0.9647\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 15:02:09.111386\n",
      "train Loss: 0.0163 Acc: 0.9928\n",
      "val Loss: 0.0427 Acc: 0.9939\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 15:02:49.419814\n",
      "train Loss: 0.0116 Acc: 0.9964\n",
      "val Loss: 0.0616 Acc: 0.9862\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 15:03:29.902852\n",
      "train Loss: 0.0062 Acc: 0.9985\n",
      "val Loss: 0.0210 Acc: 0.9954\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 15:04:10.218677\n",
      "train Loss: 0.0023 Acc: 0.9995\n",
      "val Loss: 0.0151 Acc: 0.9969\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 98 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 15:05:11.419017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6432 Acc: 0.6687\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 15:05:22.587788\n",
      "train Loss: 1.0128 Acc: 0.6469\n",
      "val Loss: 1.8481 Acc: 0.3758\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 15:06:03.089994\n",
      "train Loss: 0.4990 Acc: 0.7803\n",
      "val Loss: 0.8972 Acc: 0.5245\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 15:06:43.495353\n",
      "train Loss: 0.4766 Acc: 0.7833\n",
      "val Loss: 0.7069 Acc: 0.6549\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 15:07:23.814848\n",
      "train Loss: 0.4685 Acc: 0.7946\n",
      "val Loss: 0.5072 Acc: 0.7730\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 15:08:04.044511\n",
      "train Loss: 0.4291 Acc: 0.8181\n",
      "val Loss: 0.6178 Acc: 0.7439\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 15:08:44.276336\n",
      "train Loss: 0.4610 Acc: 0.7895\n",
      "val Loss: 0.5390 Acc: 0.7715\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 15:09:24.760751\n",
      "train Loss: 0.3994 Acc: 0.8263\n",
      "val Loss: 0.4016 Acc: 0.8113\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 15:10:04.999948\n",
      "train Loss: 0.2899 Acc: 0.8850\n",
      "val Loss: 0.5844 Acc: 0.8129\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 15:10:45.395568\n",
      "train Loss: 0.3266 Acc: 0.8636\n",
      "val Loss: 1.0300 Acc: 0.7163\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 15:11:25.808692\n",
      "train Loss: 0.2185 Acc: 0.9162\n",
      "val Loss: 0.2956 Acc: 0.8896\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 15:12:06.089068\n",
      "train Loss: 0.2468 Acc: 0.9080\n",
      "val Loss: 0.3980 Acc: 0.8604\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 15:12:46.487975\n",
      "train Loss: 0.1725 Acc: 0.9402\n",
      "val Loss: 0.6065 Acc: 0.8083\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 15:13:26.683340\n",
      "train Loss: 0.1497 Acc: 0.9402\n",
      "val Loss: 0.3360 Acc: 0.8712\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 15:14:07.240421\n",
      "train Loss: 0.1370 Acc: 0.9535\n",
      "val Loss: 0.4500 Acc: 0.8175\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 15:14:47.795230\n",
      "train Loss: 0.1131 Acc: 0.9622\n",
      "val Loss: 0.9968 Acc: 0.8834\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 15:15:28.248931\n",
      "train Loss: 0.1178 Acc: 0.9550\n",
      "val Loss: 0.2292 Acc: 0.9202\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 15:16:08.509523\n",
      "train Loss: 0.1190 Acc: 0.9607\n",
      "val Loss: 0.5926 Acc: 0.8466\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 15:16:48.942386\n",
      "train Loss: 0.1152 Acc: 0.9617\n",
      "val Loss: 0.2687 Acc: 0.9080\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 15:17:29.279140\n",
      "train Loss: 0.0612 Acc: 0.9816\n",
      "val Loss: 0.1580 Acc: 0.9310\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 15:18:09.804236\n",
      "train Loss: 0.0491 Acc: 0.9847\n",
      "val Loss: 0.7470 Acc: 0.8834\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 15:18:50.104215\n",
      "train Loss: 0.0476 Acc: 0.9842\n",
      "val Loss: 0.1836 Acc: 0.9387\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 15:19:30.530373\n",
      "train Loss: 0.0664 Acc: 0.9770\n",
      "val Loss: 0.2360 Acc: 0.9279\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 15:20:10.944938\n",
      "train Loss: 0.0946 Acc: 0.9632\n",
      "val Loss: 0.4646 Acc: 0.8942\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 15:20:51.417283\n",
      "train Loss: 0.1794 Acc: 0.9361\n",
      "val Loss: 1.0031 Acc: 0.8083\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 15:21:31.846427\n",
      "train Loss: 0.1371 Acc: 0.9479\n",
      "val Loss: 1.1170 Acc: 0.8574\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 15:22:12.256664\n",
      "train Loss: 0.0733 Acc: 0.9704\n",
      "val Loss: 0.0773 Acc: 0.9724\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 15:22:52.676133\n",
      "train Loss: 0.0481 Acc: 0.9842\n",
      "val Loss: 0.0823 Acc: 0.9663\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 15:23:32.865004\n",
      "train Loss: 0.0579 Acc: 0.9826\n",
      "val Loss: 0.1965 Acc: 0.9387\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 15:24:13.252295\n",
      "train Loss: 0.0570 Acc: 0.9816\n",
      "val Loss: 0.0930 Acc: 0.9755\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 15:24:53.687044\n",
      "train Loss: 0.0377 Acc: 0.9867\n",
      "val Loss: 0.0976 Acc: 0.9724\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 15:25:34.118792\n",
      "train Loss: 0.0241 Acc: 0.9913\n",
      "val Loss: 0.1156 Acc: 0.9571\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 15:26:14.528598\n",
      "train Loss: 0.0368 Acc: 0.9862\n",
      "val Loss: 0.5058 Acc: 0.8466\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 15:26:55.025676\n",
      "train Loss: 0.1109 Acc: 0.9637\n",
      "val Loss: 0.8131 Acc: 0.8788\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 15:27:35.382946\n",
      "train Loss: 0.0668 Acc: 0.9760\n",
      "val Loss: 0.2277 Acc: 0.9202\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 15:28:15.818441\n",
      "train Loss: 0.0465 Acc: 0.9847\n",
      "val Loss: 0.2229 Acc: 0.9463\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 15:28:56.139993\n",
      "train Loss: 0.0285 Acc: 0.9908\n",
      "val Loss: 0.0939 Acc: 0.9739\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 15:29:36.368939\n",
      "train Loss: 0.0195 Acc: 0.9934\n",
      "val Loss: 0.1293 Acc: 0.9663\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 15:30:16.783372\n",
      "train Loss: 0.0161 Acc: 0.9934\n",
      "val Loss: 0.0580 Acc: 0.9755\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 15:30:57.232479\n",
      "train Loss: 0.0131 Acc: 0.9964\n",
      "val Loss: 0.0620 Acc: 0.9816\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 15:31:37.520124\n",
      "train Loss: 0.0113 Acc: 0.9974\n",
      "val Loss: 0.1103 Acc: 0.9785\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 15:32:17.919162\n",
      "train Loss: 0.0092 Acc: 0.9964\n",
      "val Loss: 0.1307 Acc: 0.9601\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 15:32:58.443843\n",
      "train Loss: 0.0153 Acc: 0.9954\n",
      "val Loss: 0.7188 Acc: 0.9156\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 15:33:38.974619\n",
      "train Loss: 0.0214 Acc: 0.9944\n",
      "val Loss: 0.1326 Acc: 0.9709\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 15:34:19.095970\n",
      "train Loss: 0.0194 Acc: 0.9944\n",
      "val Loss: 0.0856 Acc: 0.9755\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 15:34:59.541435\n",
      "train Loss: 0.0112 Acc: 0.9964\n",
      "val Loss: 0.0629 Acc: 0.9862\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 15:35:39.742007\n",
      "train Loss: 0.0076 Acc: 0.9974\n",
      "val Loss: 0.0605 Acc: 0.9847\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 15:36:20.163062\n",
      "train Loss: 0.0227 Acc: 0.9923\n",
      "val Loss: 0.1036 Acc: 0.9724\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 15:37:00.591996\n",
      "train Loss: 0.0314 Acc: 0.9903\n",
      "val Loss: 0.2324 Acc: 0.9463\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 15:37:41.127988\n",
      "train Loss: 0.0336 Acc: 0.9908\n",
      "val Loss: 0.1811 Acc: 0.9586\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 92 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomVerticalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 15:38:42.230252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.3314 Acc: 0.6733\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 15:38:53.379836\n",
      "train Loss: 0.9315 Acc: 0.6842\n",
      "val Loss: 1.1279 Acc: 0.3267\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 15:39:33.922955\n",
      "train Loss: 0.5081 Acc: 0.7787\n",
      "val Loss: 1.0391 Acc: 0.4387\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 15:40:14.397424\n",
      "train Loss: 0.4652 Acc: 0.7966\n",
      "val Loss: 0.4812 Acc: 0.7929\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 15:40:54.973172\n",
      "train Loss: 0.4521 Acc: 0.8120\n",
      "val Loss: 0.4580 Acc: 0.8006\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 15:41:35.371592\n",
      "train Loss: 0.3887 Acc: 0.8319\n",
      "val Loss: 0.3980 Acc: 0.8359\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 15:42:15.706376\n",
      "train Loss: 0.3559 Acc: 0.8467\n",
      "val Loss: 0.7365 Acc: 0.7684\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 15:42:55.963904\n",
      "train Loss: 0.2976 Acc: 0.8840\n",
      "val Loss: 0.5738 Acc: 0.8083\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 15:43:36.324217\n",
      "train Loss: 0.2379 Acc: 0.9096\n",
      "val Loss: 0.5377 Acc: 0.7960\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 15:44:16.545786\n",
      "train Loss: 0.2162 Acc: 0.9167\n",
      "val Loss: 0.2646 Acc: 0.9141\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 15:44:56.999936\n",
      "train Loss: 0.1940 Acc: 0.9213\n",
      "val Loss: 2.8134 Acc: 0.7147\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 15:45:37.286817\n",
      "train Loss: 0.1625 Acc: 0.9382\n",
      "val Loss: 0.3626 Acc: 0.8666\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 15:46:17.618666\n",
      "train Loss: 0.1390 Acc: 0.9412\n",
      "val Loss: 0.6777 Acc: 0.7623\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 15:46:57.926025\n",
      "train Loss: 0.1807 Acc: 0.9325\n",
      "val Loss: 1.2679 Acc: 0.7745\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 15:47:38.246432\n",
      "train Loss: 0.1128 Acc: 0.9607\n",
      "val Loss: 1.1149 Acc: 0.8681\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 15:48:18.505736\n",
      "train Loss: 0.1039 Acc: 0.9642\n",
      "val Loss: 0.2316 Acc: 0.9095\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 15:48:58.768716\n",
      "train Loss: 0.1258 Acc: 0.9484\n",
      "val Loss: 0.2166 Acc: 0.9279\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 15:49:39.343118\n",
      "train Loss: 0.0891 Acc: 0.9750\n",
      "val Loss: 0.1597 Acc: 0.9325\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 15:50:19.504910\n",
      "train Loss: 0.0635 Acc: 0.9760\n",
      "val Loss: 0.1216 Acc: 0.9525\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 15:50:59.933691\n",
      "train Loss: 0.0618 Acc: 0.9765\n",
      "val Loss: 0.2830 Acc: 0.9325\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 15:51:40.296390\n",
      "train Loss: 0.1192 Acc: 0.9586\n",
      "val Loss: 0.5163 Acc: 0.8819\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 15:52:20.721338\n",
      "train Loss: 0.0700 Acc: 0.9750\n",
      "val Loss: 0.1308 Acc: 0.9509\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 15:53:00.971398\n",
      "train Loss: 0.0696 Acc: 0.9745\n",
      "val Loss: 3.8064 Acc: 0.9126\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 15:53:41.375479\n",
      "train Loss: 0.0704 Acc: 0.9770\n",
      "val Loss: 0.5636 Acc: 0.9034\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 15:54:21.770512\n",
      "train Loss: 0.0560 Acc: 0.9826\n",
      "val Loss: 0.1164 Acc: 0.9509\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 15:55:02.215924\n",
      "train Loss: 0.0515 Acc: 0.9826\n",
      "val Loss: 0.1250 Acc: 0.9525\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 15:55:42.517725\n",
      "train Loss: 0.0512 Acc: 0.9816\n",
      "val Loss: 0.3232 Acc: 0.9387\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 15:56:22.954678\n",
      "train Loss: 0.0472 Acc: 0.9806\n",
      "val Loss: 0.1459 Acc: 0.9663\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 15:57:03.445263\n",
      "train Loss: 0.0497 Acc: 0.9857\n",
      "val Loss: 0.4157 Acc: 0.8819\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 15:57:43.926377\n",
      "train Loss: 0.0747 Acc: 0.9760\n",
      "val Loss: 0.4113 Acc: 0.9156\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 15:58:24.253618\n",
      "train Loss: 0.0506 Acc: 0.9811\n",
      "val Loss: 0.3424 Acc: 0.8834\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 15:59:04.934606\n",
      "train Loss: 0.0400 Acc: 0.9872\n",
      "val Loss: 0.0469 Acc: 0.9847\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 15:59:45.555602\n",
      "train Loss: 0.0307 Acc: 0.9882\n",
      "val Loss: 0.0934 Acc: 0.9693\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 16:00:25.844377\n",
      "train Loss: 0.0521 Acc: 0.9796\n",
      "val Loss: 1.1776 Acc: 0.8957\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 16:01:06.308518\n",
      "train Loss: 0.0451 Acc: 0.9826\n",
      "val Loss: 0.2886 Acc: 0.9479\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 16:01:46.570730\n",
      "train Loss: 0.0282 Acc: 0.9923\n",
      "val Loss: 0.1244 Acc: 0.9632\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 16:02:27.072487\n",
      "train Loss: 0.0152 Acc: 0.9944\n",
      "val Loss: 0.1005 Acc: 0.9617\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 16:03:07.504009\n",
      "train Loss: 0.0128 Acc: 0.9974\n",
      "val Loss: 0.0776 Acc: 0.9693\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 16:03:47.887073\n",
      "train Loss: 0.0123 Acc: 0.9944\n",
      "val Loss: 0.1137 Acc: 0.9739\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 16:04:28.034015\n",
      "train Loss: 0.0063 Acc: 0.9980\n",
      "val Loss: 0.2665 Acc: 0.9601\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 16:05:08.367861\n",
      "train Loss: 0.0090 Acc: 0.9959\n",
      "val Loss: 0.0751 Acc: 0.9801\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 16:05:48.672088\n",
      "train Loss: 0.0164 Acc: 0.9949\n",
      "val Loss: 0.1039 Acc: 0.9709\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 16:06:28.920871\n",
      "train Loss: 0.0240 Acc: 0.9928\n",
      "val Loss: 0.0695 Acc: 0.9831\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 16:07:09.232248\n",
      "train Loss: 0.0314 Acc: 0.9898\n",
      "val Loss: 0.2805 Acc: 0.9540\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 16:07:49.485358\n",
      "train Loss: 0.0291 Acc: 0.9908\n",
      "val Loss: 0.1507 Acc: 0.9586\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 16:08:29.888766\n",
      "train Loss: 0.0232 Acc: 0.9903\n",
      "val Loss: 0.0689 Acc: 0.9847\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 16:09:10.162974\n",
      "train Loss: 0.0266 Acc: 0.9918\n",
      "val Loss: 0.1947 Acc: 0.9448\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 16:09:50.525459\n",
      "train Loss: 0.0171 Acc: 0.9954\n",
      "val Loss: 0.1130 Acc: 0.9724\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 16:10:31.025951\n",
      "train Loss: 0.0242 Acc: 0.9903\n",
      "val Loss: 0.0595 Acc: 0.9770\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 16:11:11.499975\n",
      "train Loss: 0.0187 Acc: 0.9944\n",
      "val Loss: 0.0744 Acc: 0.9755\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 96 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomRotation(degrees=(-180, 180), resample=False, expand=False)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 16:12:12.259498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.2079 Acc: 0.6733\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 16:12:23.310520\n",
      "train Loss: 0.9335 Acc: 0.6771\n",
      "val Loss: 2.0381 Acc: 0.6380\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 16:13:03.971877\n",
      "train Loss: 0.5048 Acc: 0.7798\n",
      "val Loss: 0.9875 Acc: 0.5982\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 16:13:44.511640\n",
      "train Loss: 0.4811 Acc: 0.7879\n",
      "val Loss: 0.5609 Acc: 0.7638\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 16:14:25.220296\n",
      "train Loss: 0.4918 Acc: 0.7782\n",
      "val Loss: 0.5638 Acc: 0.7408\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 16:15:05.742110\n",
      "train Loss: 0.4758 Acc: 0.7895\n",
      "val Loss: 0.5212 Acc: 0.7730\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 16:15:46.022512\n",
      "train Loss: 0.4521 Acc: 0.8012\n",
      "val Loss: 0.5155 Acc: 0.7807\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 16:16:26.472784\n",
      "train Loss: 0.4197 Acc: 0.8283\n",
      "val Loss: 0.5270 Acc: 0.8037\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 16:17:07.261796\n",
      "train Loss: 0.4529 Acc: 0.8043\n",
      "val Loss: 0.4875 Acc: 0.7822\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 16:17:47.858153\n",
      "train Loss: 0.4337 Acc: 0.8114\n",
      "val Loss: 0.4967 Acc: 0.7914\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 16:18:28.401695\n",
      "train Loss: 0.4307 Acc: 0.8196\n",
      "val Loss: 0.5062 Acc: 0.7991\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 16:19:08.946841\n",
      "train Loss: 0.4185 Acc: 0.8242\n",
      "val Loss: 0.5080 Acc: 0.7975\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 16:19:49.511288\n",
      "train Loss: 0.3640 Acc: 0.8477\n",
      "val Loss: 0.6292 Acc: 0.7592\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 16:20:30.104706\n",
      "train Loss: 0.3904 Acc: 0.8416\n",
      "val Loss: 0.4510 Acc: 0.8021\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 16:21:10.714516\n",
      "train Loss: 0.4116 Acc: 0.8298\n",
      "val Loss: 0.4359 Acc: 0.8175\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 16:21:51.207598\n",
      "train Loss: 0.4332 Acc: 0.8150\n",
      "val Loss: 0.5097 Acc: 0.7546\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 16:22:31.765111\n",
      "train Loss: 0.3849 Acc: 0.8344\n",
      "val Loss: 0.3899 Acc: 0.8344\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 16:23:12.163793\n",
      "train Loss: 0.3734 Acc: 0.8533\n",
      "val Loss: 0.4417 Acc: 0.8298\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 16:23:52.535317\n",
      "train Loss: 0.3404 Acc: 0.8539\n",
      "val Loss: 0.5518 Acc: 0.8390\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 16:24:32.905967\n",
      "train Loss: 0.3606 Acc: 0.8493\n",
      "val Loss: 0.5831 Acc: 0.8252\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 16:25:13.324922\n",
      "train Loss: 0.3213 Acc: 0.8641\n",
      "val Loss: 0.4204 Acc: 0.8160\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 16:25:53.928042\n",
      "train Loss: 0.3304 Acc: 0.8666\n",
      "val Loss: 0.3750 Acc: 0.8543\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 16:26:34.455910\n",
      "train Loss: 0.3111 Acc: 0.8815\n",
      "val Loss: 0.9154 Acc: 0.7209\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 16:27:14.828822\n",
      "train Loss: 0.3994 Acc: 0.8426\n",
      "val Loss: 0.5937 Acc: 0.7914\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 16:27:55.249641\n",
      "train Loss: 0.3163 Acc: 0.8682\n",
      "val Loss: 0.4943 Acc: 0.7945\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 16:28:35.491977\n",
      "train Loss: 0.2416 Acc: 0.9029\n",
      "val Loss: 0.3341 Acc: 0.8712\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 16:29:16.013341\n",
      "train Loss: 0.2115 Acc: 0.9218\n",
      "val Loss: 0.8048 Acc: 0.6012\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 16:29:56.655229\n",
      "train Loss: 0.3237 Acc: 0.8687\n",
      "val Loss: 0.5604 Acc: 0.7699\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 16:30:36.875383\n",
      "train Loss: 0.3020 Acc: 0.8763\n",
      "val Loss: 0.4071 Acc: 0.8574\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 16:31:17.261489\n",
      "train Loss: 0.3382 Acc: 0.8774\n",
      "val Loss: 0.3580 Acc: 0.8497\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 16:31:57.624731\n",
      "train Loss: 0.2957 Acc: 0.8855\n",
      "val Loss: 0.5005 Acc: 0.8344\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 16:32:38.029372\n",
      "train Loss: 0.2403 Acc: 0.9029\n",
      "val Loss: 0.8476 Acc: 0.7393\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 16:33:18.485365\n",
      "train Loss: 0.2692 Acc: 0.9044\n",
      "val Loss: 0.5596 Acc: 0.7439\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 16:33:58.692094\n",
      "train Loss: 0.2758 Acc: 0.8896\n",
      "val Loss: 0.2428 Acc: 0.9080\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 16:34:39.168601\n",
      "train Loss: 0.2454 Acc: 0.9070\n",
      "val Loss: 0.3364 Acc: 0.8528\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 16:35:19.580411\n",
      "train Loss: 0.2365 Acc: 0.9106\n",
      "val Loss: 0.1807 Acc: 0.9340\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 16:36:00.208338\n",
      "train Loss: 0.2024 Acc: 0.9213\n",
      "val Loss: 0.4794 Acc: 0.8144\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 16:36:40.499910\n",
      "train Loss: 0.1890 Acc: 0.9341\n",
      "val Loss: 0.4237 Acc: 0.8742\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 16:37:21.042230\n",
      "train Loss: 0.1535 Acc: 0.9474\n",
      "val Loss: 0.1021 Acc: 0.9678\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 16:38:01.446227\n",
      "train Loss: 0.1431 Acc: 0.9458\n",
      "val Loss: 0.2329 Acc: 0.9064\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 16:38:41.975920\n",
      "train Loss: 0.1737 Acc: 0.9392\n",
      "val Loss: 0.2065 Acc: 0.9126\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 16:39:22.342871\n",
      "train Loss: 0.1428 Acc: 0.9494\n",
      "val Loss: 0.2026 Acc: 0.9141\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 16:40:02.612947\n",
      "train Loss: 0.1488 Acc: 0.9417\n",
      "val Loss: 1.0864 Acc: 0.5322\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 16:40:43.086299\n",
      "train Loss: 0.1636 Acc: 0.9351\n",
      "val Loss: 0.3632 Acc: 0.8758\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 16:41:23.546472\n",
      "train Loss: 0.1633 Acc: 0.9407\n",
      "val Loss: 0.2026 Acc: 0.9003\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 16:42:04.196889\n",
      "train Loss: 0.1150 Acc: 0.9668\n",
      "val Loss: 0.2363 Acc: 0.9049\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 16:42:44.640812\n",
      "train Loss: 0.1132 Acc: 0.9617\n",
      "val Loss: 0.2174 Acc: 0.9095\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 16:43:24.982181\n",
      "train Loss: 0.1779 Acc: 0.9356\n",
      "val Loss: 0.1837 Acc: 0.9187\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 16:44:05.620334\n",
      "train Loss: 0.1342 Acc: 0.9515\n",
      "val Loss: 0.2328 Acc: 0.9248\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 16:44:45.992905\n",
      "train Loss: 0.1358 Acc: 0.9530\n",
      "val Loss: 0.2617 Acc: 0.8819\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 86 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomPerspective(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 16:45:47.171276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 5.4565 Acc: 0.3267\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 16:45:58.261171\n",
      "train Loss: 0.8556 Acc: 0.6735\n",
      "val Loss: 0.6188 Acc: 0.6764\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 16:46:39.939076\n",
      "train Loss: 0.5023 Acc: 0.7777\n",
      "val Loss: 0.7222 Acc: 0.7101\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 16:47:21.521833\n",
      "train Loss: 0.4896 Acc: 0.7721\n",
      "val Loss: 0.5711 Acc: 0.7546\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 16:48:02.987679\n",
      "train Loss: 0.4590 Acc: 0.7951\n",
      "val Loss: 0.5141 Acc: 0.7791\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 16:48:44.889716\n",
      "train Loss: 0.4565 Acc: 0.8028\n",
      "val Loss: 0.6204 Acc: 0.7301\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 16:49:26.634802\n",
      "train Loss: 0.4047 Acc: 0.8314\n",
      "val Loss: 1.0158 Acc: 0.6979\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 16:50:08.016995\n",
      "train Loss: 0.3899 Acc: 0.8508\n",
      "val Loss: 0.6370 Acc: 0.8144\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 16:50:49.683902\n",
      "train Loss: 0.3252 Acc: 0.8723\n",
      "val Loss: 0.6254 Acc: 0.7561\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 16:51:31.156692\n",
      "train Loss: 0.2846 Acc: 0.8978\n",
      "val Loss: 0.4764 Acc: 0.8113\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 16:52:12.476657\n",
      "train Loss: 0.2336 Acc: 0.9101\n",
      "val Loss: 0.4923 Acc: 0.8620\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 16:52:53.936957\n",
      "train Loss: 0.2672 Acc: 0.8958\n",
      "val Loss: 2.3583 Acc: 0.7270\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 16:53:35.413694\n",
      "train Loss: 0.2007 Acc: 0.9136\n",
      "val Loss: 0.7795 Acc: 0.7147\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 16:54:17.135621\n",
      "train Loss: 0.1391 Acc: 0.9469\n",
      "val Loss: 0.1379 Acc: 0.9509\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 16:54:58.591020\n",
      "train Loss: 0.1680 Acc: 0.9371\n",
      "val Loss: 0.1952 Acc: 0.9509\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 16:55:40.118733\n",
      "train Loss: 0.1592 Acc: 0.9351\n",
      "val Loss: 0.4645 Acc: 0.8436\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 16:56:21.533717\n",
      "train Loss: 0.1212 Acc: 0.9428\n",
      "val Loss: 1.1535 Acc: 0.8160\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 16:57:02.861999\n",
      "train Loss: 0.0970 Acc: 0.9658\n",
      "val Loss: 0.0899 Acc: 0.9571\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 16:57:44.365394\n",
      "train Loss: 0.1233 Acc: 0.9653\n",
      "val Loss: 0.1870 Acc: 0.9310\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 16:58:26.691019\n",
      "train Loss: 0.1022 Acc: 0.9642\n",
      "val Loss: 0.0653 Acc: 0.9755\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 16:59:08.616335\n",
      "train Loss: 0.0595 Acc: 0.9796\n",
      "val Loss: 0.9984 Acc: 0.9172\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 16:59:50.556053\n",
      "train Loss: 0.0610 Acc: 0.9821\n",
      "val Loss: 0.1781 Acc: 0.9218\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 17:00:32.308145\n",
      "train Loss: 0.0526 Acc: 0.9821\n",
      "val Loss: 0.0278 Acc: 0.9908\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 17:01:13.766208\n",
      "train Loss: 0.0433 Acc: 0.9847\n",
      "val Loss: 0.0702 Acc: 0.9877\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 17:01:55.224938\n",
      "train Loss: 0.0554 Acc: 0.9806\n",
      "val Loss: 0.6712 Acc: 0.9202\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 17:02:36.596041\n",
      "train Loss: 0.0508 Acc: 0.9852\n",
      "val Loss: 0.4833 Acc: 0.9126\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 17:03:18.203632\n",
      "train Loss: 0.0518 Acc: 0.9806\n",
      "val Loss: 0.1143 Acc: 0.9632\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 17:03:59.660977\n",
      "train Loss: 0.0451 Acc: 0.9872\n",
      "val Loss: 0.1398 Acc: 0.9479\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 17:04:41.196590\n",
      "train Loss: 0.1493 Acc: 0.9438\n",
      "val Loss: 0.4078 Acc: 0.8819\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 17:05:22.763866\n",
      "train Loss: 0.0684 Acc: 0.9780\n",
      "val Loss: 0.0577 Acc: 0.9862\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 17:06:04.206821\n",
      "train Loss: 0.0436 Acc: 0.9888\n",
      "val Loss: 0.0538 Acc: 0.9816\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 17:06:45.524522\n",
      "train Loss: 0.0601 Acc: 0.9811\n",
      "val Loss: 0.7874 Acc: 0.9402\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 17:07:26.925654\n",
      "train Loss: 0.0496 Acc: 0.9836\n",
      "val Loss: 0.1144 Acc: 0.9448\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 17:08:08.244530\n",
      "train Loss: 0.0486 Acc: 0.9852\n",
      "val Loss: 0.0571 Acc: 0.9770\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 17:08:49.487627\n",
      "train Loss: 0.0379 Acc: 0.9877\n",
      "val Loss: 0.0806 Acc: 0.9755\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 17:09:30.890666\n",
      "train Loss: 0.0273 Acc: 0.9918\n",
      "val Loss: 0.0217 Acc: 0.9954\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 17:10:12.253613\n",
      "train Loss: 0.0343 Acc: 0.9908\n",
      "val Loss: 0.0203 Acc: 0.9923\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 17:10:53.764147\n",
      "train Loss: 0.0383 Acc: 0.9882\n",
      "val Loss: 0.0145 Acc: 0.9954\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 17:11:35.015511\n",
      "train Loss: 0.0328 Acc: 0.9903\n",
      "val Loss: 0.0120 Acc: 0.9939\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 17:12:16.386689\n",
      "train Loss: 0.0238 Acc: 0.9934\n",
      "val Loss: 0.0099 Acc: 0.9954\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 17:12:57.735956\n",
      "train Loss: 0.0364 Acc: 0.9913\n",
      "val Loss: 0.0688 Acc: 0.9693\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 17:13:39.305104\n",
      "train Loss: 0.0280 Acc: 0.9923\n",
      "val Loss: 0.0598 Acc: 0.9785\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 17:14:20.661806\n",
      "train Loss: 0.0621 Acc: 0.9821\n",
      "val Loss: 0.0479 Acc: 0.9739\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 17:15:02.180307\n",
      "train Loss: 0.0283 Acc: 0.9913\n",
      "val Loss: 0.1065 Acc: 0.9479\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 17:15:43.742945\n",
      "train Loss: 0.0176 Acc: 0.9944\n",
      "val Loss: 0.0142 Acc: 0.9969\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 17:16:25.235315\n",
      "train Loss: 0.0122 Acc: 0.9954\n",
      "val Loss: 0.0083 Acc: 0.9969\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 17:17:06.590258\n",
      "train Loss: 0.0193 Acc: 0.9959\n",
      "val Loss: 0.0534 Acc: 0.9862\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 17:17:48.136964\n",
      "train Loss: 0.0171 Acc: 0.9944\n",
      "val Loss: 0.0160 Acc: 0.9939\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 17:18:29.325928\n",
      "train Loss: 0.0206 Acc: 0.9934\n",
      "val Loss: 0.0153 Acc: 0.9939\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 17:19:10.672924\n",
      "train Loss: 0.0215 Acc: 0.9928\n",
      "val Loss: 0.0117 Acc: 0.9939\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 98 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 17:20:12.537852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9535 Acc: 0.6733\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 17:20:23.580246\n",
      "train Loss: 0.9048 Acc: 0.6863\n",
      "val Loss: 1.1702 Acc: 0.3819\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 17:21:04.480602\n",
      "train Loss: 0.5277 Acc: 0.7639\n",
      "val Loss: 0.8482 Acc: 0.6580\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 17:21:45.371798\n",
      "train Loss: 0.5020 Acc: 0.7716\n",
      "val Loss: 0.4993 Acc: 0.7837\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 17:22:26.148353\n",
      "train Loss: 0.4823 Acc: 0.7895\n",
      "val Loss: 0.5055 Acc: 0.7837\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 17:23:07.125457\n",
      "train Loss: 0.4595 Acc: 0.8022\n",
      "val Loss: 0.4631 Acc: 0.7868\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 17:23:48.084067\n",
      "train Loss: 0.4669 Acc: 0.7920\n",
      "val Loss: 0.4660 Acc: 0.7991\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 17:24:28.786293\n",
      "train Loss: 0.4618 Acc: 0.7941\n",
      "val Loss: 0.4920 Acc: 0.7715\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 17:25:09.593310\n",
      "train Loss: 0.4600 Acc: 0.7976\n",
      "val Loss: 0.5893 Acc: 0.7761\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 17:25:50.328928\n",
      "train Loss: 0.4454 Acc: 0.8135\n",
      "val Loss: 1.0250 Acc: 0.5690\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 17:26:31.216281\n",
      "train Loss: 0.4207 Acc: 0.8181\n",
      "val Loss: 0.5410 Acc: 0.7623\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 17:27:12.162232\n",
      "train Loss: 0.4158 Acc: 0.8278\n",
      "val Loss: 0.5927 Acc: 0.7301\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 17:27:52.997156\n",
      "train Loss: 0.4377 Acc: 0.8232\n",
      "val Loss: 2.7320 Acc: 0.6963\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 17:28:33.730807\n",
      "train Loss: 0.4312 Acc: 0.8217\n",
      "val Loss: 0.4442 Acc: 0.8206\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 17:29:14.908591\n",
      "train Loss: 0.4564 Acc: 0.8140\n",
      "val Loss: 2.4972 Acc: 0.5184\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 17:29:55.724549\n",
      "train Loss: 0.4067 Acc: 0.8242\n",
      "val Loss: 0.3990 Acc: 0.8758\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 17:30:36.612858\n",
      "train Loss: 0.3787 Acc: 0.8396\n",
      "val Loss: 0.3277 Acc: 0.8758\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 17:31:17.325188\n",
      "train Loss: 0.3611 Acc: 0.8539\n",
      "val Loss: 0.3682 Acc: 0.8620\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 17:31:58.062677\n",
      "train Loss: 0.3762 Acc: 0.8406\n",
      "val Loss: 0.5503 Acc: 0.7469\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 17:32:38.742334\n",
      "train Loss: 0.3492 Acc: 0.8554\n",
      "val Loss: 0.2647 Acc: 0.8926\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 17:33:19.518773\n",
      "train Loss: 0.3448 Acc: 0.8544\n",
      "val Loss: 0.3369 Acc: 0.8727\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 17:34:00.346106\n",
      "train Loss: 0.3486 Acc: 0.8539\n",
      "val Loss: 0.4845 Acc: 0.8451\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 17:34:40.986415\n",
      "train Loss: 0.3303 Acc: 0.8610\n",
      "val Loss: 0.4192 Acc: 0.8497\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 17:35:21.886766\n",
      "train Loss: 0.3570 Acc: 0.8610\n",
      "val Loss: 0.2481 Acc: 0.9156\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 17:36:02.739550\n",
      "train Loss: 0.3099 Acc: 0.8809\n",
      "val Loss: 0.2324 Acc: 0.9187\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 17:36:43.608156\n",
      "train Loss: 0.3021 Acc: 0.8753\n",
      "val Loss: 0.5649 Acc: 0.8681\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 17:37:24.316610\n",
      "train Loss: 0.2693 Acc: 0.8968\n",
      "val Loss: 0.3050 Acc: 0.8727\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 17:38:04.886376\n",
      "train Loss: 0.2521 Acc: 0.8993\n",
      "val Loss: 0.3316 Acc: 0.8988\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 17:38:45.594032\n",
      "train Loss: 0.2636 Acc: 0.8932\n",
      "val Loss: 0.7048 Acc: 0.7485\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 17:39:26.223251\n",
      "train Loss: 0.2812 Acc: 0.8830\n",
      "val Loss: 0.2585 Acc: 0.8880\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 17:40:06.921910\n",
      "train Loss: 0.2565 Acc: 0.8937\n",
      "val Loss: 0.1585 Acc: 0.9402\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 17:40:47.600316\n",
      "train Loss: 0.2401 Acc: 0.9055\n",
      "val Loss: 0.5063 Acc: 0.8175\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 17:41:28.401658\n",
      "train Loss: 0.2355 Acc: 0.9090\n",
      "val Loss: 0.3002 Acc: 0.8957\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 17:42:09.566643\n",
      "train Loss: 0.2601 Acc: 0.9014\n",
      "val Loss: 0.4716 Acc: 0.9064\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 17:42:50.366088\n",
      "train Loss: 0.2187 Acc: 0.9106\n",
      "val Loss: 0.1979 Acc: 0.9387\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 17:43:31.194130\n",
      "train Loss: 0.2354 Acc: 0.9050\n",
      "val Loss: 1.2935 Acc: 0.8911\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 17:44:11.629907\n",
      "train Loss: 0.2717 Acc: 0.8968\n",
      "val Loss: 0.3828 Acc: 0.8589\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 17:44:52.018663\n",
      "train Loss: 0.2149 Acc: 0.9136\n",
      "val Loss: 0.8018 Acc: 0.9248\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 17:45:32.560373\n",
      "train Loss: 0.2206 Acc: 0.9111\n",
      "val Loss: 0.1706 Acc: 0.9402\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 17:46:13.351023\n",
      "train Loss: 0.2477 Acc: 0.9075\n",
      "val Loss: 0.2064 Acc: 0.9202\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 17:46:54.230194\n",
      "train Loss: 0.2229 Acc: 0.9136\n",
      "val Loss: 0.1506 Acc: 0.9371\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 17:47:35.136230\n",
      "train Loss: 0.2381 Acc: 0.9060\n",
      "val Loss: 0.1982 Acc: 0.9218\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 17:48:15.753525\n",
      "train Loss: 0.2250 Acc: 0.9152\n",
      "val Loss: 0.4245 Acc: 0.9034\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 17:48:56.510434\n",
      "train Loss: 0.2219 Acc: 0.9157\n",
      "val Loss: 0.6512 Acc: 0.6779\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 17:49:37.366531\n",
      "train Loss: 0.2147 Acc: 0.9177\n",
      "val Loss: 0.1037 Acc: 0.9555\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 17:50:18.137781\n",
      "train Loss: 0.2123 Acc: 0.9106\n",
      "val Loss: 0.0662 Acc: 0.9739\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 17:50:59.014075\n",
      "train Loss: 0.1903 Acc: 0.9346\n",
      "val Loss: 0.0840 Acc: 0.9709\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 17:51:39.598934\n",
      "train Loss: 0.2066 Acc: 0.9244\n",
      "val Loss: 0.1533 Acc: 0.9417\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 17:52:20.362652\n",
      "train Loss: 0.2239 Acc: 0.9090\n",
      "val Loss: 0.5272 Acc: 0.9126\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 17:53:01.090590\n",
      "train Loss: 0.2078 Acc: 0.9172\n",
      "val Loss: 0.1427 Acc: 0.9571\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 95 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    <torchvision.transforms.transforms.RandomErasing object at 0x7f5603813320>\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 17:54:02.541149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.1361 Acc: 0.3267\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 17:54:13.650553\n",
      "train Loss: 1.1375 Acc: 0.6546\n",
      "val Loss: 1.7451 Acc: 0.6610\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 17:54:54.034979\n",
      "train Loss: 0.5243 Acc: 0.7639\n",
      "val Loss: 0.5324 Acc: 0.7546\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 17:55:34.294325\n",
      "train Loss: 0.5114 Acc: 0.7823\n",
      "val Loss: 0.5118 Acc: 0.7914\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 17:56:14.771394\n",
      "train Loss: 0.4975 Acc: 0.7854\n",
      "val Loss: 0.4797 Acc: 0.8067\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 17:56:55.216258\n",
      "train Loss: 0.4587 Acc: 0.8079\n",
      "val Loss: 0.4262 Acc: 0.8344\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 17:57:35.704358\n",
      "train Loss: 0.4618 Acc: 0.8068\n",
      "val Loss: 0.4795 Acc: 0.7853\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 17:58:15.989137\n",
      "train Loss: 0.4345 Acc: 0.8196\n",
      "val Loss: 0.5739 Acc: 0.7745\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 17:58:56.611942\n",
      "train Loss: 0.4163 Acc: 0.8324\n",
      "val Loss: 0.3062 Acc: 0.8911\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 17:59:37.176881\n",
      "train Loss: 0.3504 Acc: 0.8569\n",
      "val Loss: 0.4337 Acc: 0.8528\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 18:00:17.523572\n",
      "train Loss: 0.3587 Acc: 0.8559\n",
      "val Loss: 0.4151 Acc: 0.8758\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 18:00:57.803682\n",
      "train Loss: 0.3451 Acc: 0.8625\n",
      "val Loss: 2.9591 Acc: 0.5153\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 18:01:37.979589\n",
      "train Loss: 0.2929 Acc: 0.8896\n",
      "val Loss: 0.2947 Acc: 0.8819\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 18:02:18.381910\n",
      "train Loss: 0.2492 Acc: 0.9019\n",
      "val Loss: 0.4284 Acc: 0.9172\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 18:02:58.754324\n",
      "train Loss: 0.2073 Acc: 0.9264\n",
      "val Loss: 0.2138 Acc: 0.9049\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 18:03:39.004240\n",
      "train Loss: 0.2152 Acc: 0.9182\n",
      "val Loss: 0.1097 Acc: 0.9525\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 18:04:19.421881\n",
      "train Loss: 0.2201 Acc: 0.9193\n",
      "val Loss: 0.2241 Acc: 0.9325\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 18:04:59.816515\n",
      "train Loss: 0.2192 Acc: 0.9126\n",
      "val Loss: 0.2866 Acc: 0.8972\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 18:05:40.227309\n",
      "train Loss: 0.1801 Acc: 0.9341\n",
      "val Loss: 0.2862 Acc: 0.8819\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 18:06:20.310824\n",
      "train Loss: 0.1674 Acc: 0.9423\n",
      "val Loss: 0.0396 Acc: 0.9831\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 18:07:00.812555\n",
      "train Loss: 0.1359 Acc: 0.9504\n",
      "val Loss: 0.4427 Acc: 0.7055\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 18:07:41.346093\n",
      "train Loss: 0.1388 Acc: 0.9540\n",
      "val Loss: 0.0315 Acc: 0.9893\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 18:08:21.776426\n",
      "train Loss: 0.1103 Acc: 0.9627\n",
      "val Loss: 0.0573 Acc: 0.9893\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 18:09:02.027338\n",
      "train Loss: 0.0894 Acc: 0.9683\n",
      "val Loss: 0.0402 Acc: 0.9893\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 18:09:42.379536\n",
      "train Loss: 0.1285 Acc: 0.9520\n",
      "val Loss: 0.0468 Acc: 0.9831\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 18:10:22.772918\n",
      "train Loss: 0.1295 Acc: 0.9530\n",
      "val Loss: 0.1294 Acc: 0.9739\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 18:11:02.985068\n",
      "train Loss: 0.0936 Acc: 0.9724\n",
      "val Loss: 0.0499 Acc: 0.9862\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 18:11:43.407841\n",
      "train Loss: 0.0794 Acc: 0.9719\n",
      "val Loss: 0.0269 Acc: 0.9923\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 18:12:23.862326\n",
      "train Loss: 0.1038 Acc: 0.9622\n",
      "val Loss: 0.2572 Acc: 0.9294\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 18:13:04.306266\n",
      "train Loss: 0.1159 Acc: 0.9637\n",
      "val Loss: 0.0723 Acc: 0.9862\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 18:13:44.688705\n",
      "train Loss: 0.0962 Acc: 0.9668\n",
      "val Loss: 0.0662 Acc: 0.9893\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 18:14:25.111873\n",
      "train Loss: 0.0783 Acc: 0.9724\n",
      "val Loss: 0.0321 Acc: 0.9908\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 18:15:05.527608\n",
      "train Loss: 0.0882 Acc: 0.9709\n",
      "val Loss: 0.4256 Acc: 0.6994\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 18:15:46.094286\n",
      "train Loss: 0.0823 Acc: 0.9663\n",
      "val Loss: 0.0399 Acc: 0.9862\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 18:16:26.714240\n",
      "train Loss: 0.0859 Acc: 0.9709\n",
      "val Loss: 0.0408 Acc: 0.9954\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 18:17:07.212399\n",
      "train Loss: 0.0662 Acc: 0.9760\n",
      "val Loss: 0.0595 Acc: 0.9877\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 18:17:47.688421\n",
      "train Loss: 0.0753 Acc: 0.9739\n",
      "val Loss: 0.0135 Acc: 0.9939\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 18:18:28.004667\n",
      "train Loss: 0.0859 Acc: 0.9693\n",
      "val Loss: 0.0475 Acc: 0.9739\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 18:19:08.396448\n",
      "train Loss: 0.0833 Acc: 0.9688\n",
      "val Loss: 0.6506 Acc: 0.9218\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 18:19:48.857743\n",
      "train Loss: 0.1179 Acc: 0.9586\n",
      "val Loss: 0.2111 Acc: 0.9080\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 18:20:29.206374\n",
      "train Loss: 0.0754 Acc: 0.9704\n",
      "val Loss: 0.0189 Acc: 0.9954\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 18:21:09.350048\n",
      "train Loss: 0.0547 Acc: 0.9806\n",
      "val Loss: 0.0317 Acc: 0.9954\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 18:21:49.856494\n",
      "train Loss: 0.0438 Acc: 0.9867\n",
      "val Loss: 0.0364 Acc: 0.9923\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 18:22:30.301592\n",
      "train Loss: 0.0488 Acc: 0.9847\n",
      "val Loss: 0.0440 Acc: 0.9862\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 18:23:10.795275\n",
      "train Loss: 0.0512 Acc: 0.9821\n",
      "val Loss: 0.0278 Acc: 0.9893\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 18:23:51.076667\n",
      "train Loss: 0.0540 Acc: 0.9826\n",
      "val Loss: 0.0360 Acc: 0.9939\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 18:24:31.543166\n",
      "train Loss: 0.0483 Acc: 0.9836\n",
      "val Loss: 0.0215 Acc: 0.9954\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 18:25:11.960222\n",
      "train Loss: 0.0357 Acc: 0.9857\n",
      "val Loss: 0.0087 Acc: 0.9969\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 18:25:52.313272\n",
      "train Loss: 0.0421 Acc: 0.9852\n",
      "val Loss: 0.0499 Acc: 0.9801\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 18:26:32.343554\n",
      "train Loss: 0.0363 Acc: 0.9872\n",
      "val Loss: 0.0395 Acc: 0.9816\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 97 %\n",
      "乱数シード=1\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 18:27:34.073978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 3.8978 Acc: 0.3267\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 18:27:45.160566\n",
      "train Loss: 0.9603 Acc: 0.6638\n",
      "val Loss: 0.5726 Acc: 0.7239\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 18:28:25.396636\n",
      "train Loss: 0.4778 Acc: 0.7808\n",
      "val Loss: 1.1002 Acc: 0.4248\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 18:29:05.704172\n",
      "train Loss: 0.3609 Acc: 0.8365\n",
      "val Loss: 0.5107 Acc: 0.7791\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 18:29:45.871303\n",
      "train Loss: 0.2487 Acc: 0.8973\n",
      "val Loss: 0.6660 Acc: 0.8037\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 18:30:25.861473\n",
      "train Loss: 0.1593 Acc: 0.9361\n",
      "val Loss: 0.5255 Acc: 0.8742\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 18:31:06.245213\n",
      "train Loss: 0.1102 Acc: 0.9653\n",
      "val Loss: 0.1227 Acc: 0.9555\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 18:31:46.551538\n",
      "train Loss: 0.0733 Acc: 0.9775\n",
      "val Loss: 0.1995 Acc: 0.9325\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 18:32:26.833444\n",
      "train Loss: 0.0693 Acc: 0.9755\n",
      "val Loss: 0.4034 Acc: 0.8911\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 18:33:07.142298\n",
      "train Loss: 0.0786 Acc: 0.9719\n",
      "val Loss: 1.1781 Acc: 0.8911\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 18:33:47.395283\n",
      "train Loss: 0.0535 Acc: 0.9811\n",
      "val Loss: 0.3680 Acc: 0.8926\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 18:34:27.537017\n",
      "train Loss: 0.0525 Acc: 0.9801\n",
      "val Loss: 0.2326 Acc: 0.9202\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 18:35:07.913575\n",
      "train Loss: 0.0457 Acc: 0.9842\n",
      "val Loss: 0.3136 Acc: 0.9356\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 18:35:48.212324\n",
      "train Loss: 0.0510 Acc: 0.9852\n",
      "val Loss: 0.1939 Acc: 0.9402\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 18:36:28.569049\n",
      "train Loss: 0.0664 Acc: 0.9760\n",
      "val Loss: 0.1755 Acc: 0.9463\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 18:37:08.971267\n",
      "train Loss: 0.0346 Acc: 0.9872\n",
      "val Loss: 0.0542 Acc: 0.9862\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 18:37:49.363661\n",
      "train Loss: 0.0213 Acc: 0.9944\n",
      "val Loss: 0.0800 Acc: 0.9739\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 18:38:29.388180\n",
      "train Loss: 0.0245 Acc: 0.9913\n",
      "val Loss: 0.1056 Acc: 0.9632\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 18:39:09.504139\n",
      "train Loss: 0.0126 Acc: 0.9954\n",
      "val Loss: 0.0791 Acc: 0.9724\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 18:39:49.748664\n",
      "train Loss: 0.0083 Acc: 0.9974\n",
      "val Loss: 0.0461 Acc: 0.9816\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 18:40:30.010898\n",
      "train Loss: 0.0018 Acc: 1.0000\n",
      "val Loss: 0.0504 Acc: 0.9862\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 18:41:10.416864\n",
      "train Loss: 0.0017 Acc: 0.9995\n",
      "val Loss: 0.1681 Acc: 0.9586\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 18:41:50.681443\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "val Loss: 0.0483 Acc: 0.9877\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 18:42:30.823840\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "val Loss: 0.0481 Acc: 0.9877\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 18:43:10.863219\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "val Loss: 0.0405 Acc: 0.9923\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 18:43:51.076728\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "val Loss: 0.0390 Acc: 0.9862\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 18:44:31.292563\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "val Loss: 0.0475 Acc: 0.9877\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 18:45:11.417987\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 0.0508 Acc: 0.9862\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 18:45:51.665642\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0527 Acc: 0.9862\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 18:46:31.693801\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0446 Acc: 0.9862\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 18:47:11.736045\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0456 Acc: 0.9862\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 18:47:52.028205\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0470 Acc: 0.9862\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 18:48:32.309838\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0465 Acc: 0.9862\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 18:49:12.654009\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0422 Acc: 0.9893\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 18:49:52.789995\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0449 Acc: 0.9877\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 18:50:33.160899\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0466 Acc: 0.9862\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 18:51:13.105520\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0428 Acc: 0.9877\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 18:51:53.439832\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0509 Acc: 0.9862\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 18:52:33.689943\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 0.0418 Acc: 0.9893\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 18:53:13.980558\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0433 Acc: 0.9877\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 18:53:54.570038\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0422 Acc: 0.9908\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 18:54:34.826553\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0443 Acc: 0.9877\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 18:55:14.962741\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0440 Acc: 0.9877\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 18:55:55.170009\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0466 Acc: 0.9847\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 18:56:35.602455\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0451 Acc: 0.9877\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 18:57:15.722049\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0434 Acc: 0.9893\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 18:57:55.814930\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0443 Acc: 0.9893\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 18:58:35.904414\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0450 Acc: 0.9877\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 18:59:16.039587\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0450 Acc: 0.9908\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 18:59:56.324873\n",
      "train Loss: 0.0000 Acc: 1.0000\n",
      "val Loss: 0.0465 Acc: 0.9877\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 98 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 19:00:57.443523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5759 Acc: 0.6748\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 19:01:08.528156\n",
      "train Loss: 0.9885 Acc: 0.6638\n",
      "val Loss: 0.5720 Acc: 0.6917\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 19:01:48.883414\n",
      "train Loss: 0.4704 Acc: 0.7931\n",
      "val Loss: 0.7086 Acc: 0.6779\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 19:02:29.213511\n",
      "train Loss: 0.4260 Acc: 0.8094\n",
      "val Loss: 0.4905 Acc: 0.7883\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 19:03:09.457489\n",
      "train Loss: 0.4260 Acc: 0.8196\n",
      "val Loss: 0.9832 Acc: 0.7699\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 19:03:49.741854\n",
      "train Loss: 0.3710 Acc: 0.8467\n",
      "val Loss: 0.4056 Acc: 0.8083\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 19:04:30.118373\n",
      "train Loss: 0.2967 Acc: 0.8784\n",
      "val Loss: 0.9912 Acc: 0.8298\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 19:05:10.507555\n",
      "train Loss: 0.2641 Acc: 0.9044\n",
      "val Loss: 0.7768 Acc: 0.7117\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 19:05:50.661187\n",
      "train Loss: 0.2511 Acc: 0.9019\n",
      "val Loss: 0.2839 Acc: 0.8972\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 19:06:31.080997\n",
      "train Loss: 0.2279 Acc: 0.9244\n",
      "val Loss: 0.4827 Acc: 0.8298\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 19:07:11.242735\n",
      "train Loss: 0.2005 Acc: 0.9213\n",
      "val Loss: 0.4096 Acc: 0.8650\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 19:07:51.613203\n",
      "train Loss: 0.1539 Acc: 0.9361\n",
      "val Loss: 0.7514 Acc: 0.7178\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 19:08:31.898299\n",
      "train Loss: 0.1295 Acc: 0.9515\n",
      "val Loss: 0.5181 Acc: 0.8957\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 19:09:12.263598\n",
      "train Loss: 0.0797 Acc: 0.9714\n",
      "val Loss: 0.1248 Acc: 0.9509\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 19:09:52.521702\n",
      "train Loss: 0.0610 Acc: 0.9801\n",
      "val Loss: 0.1952 Acc: 0.9494\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 19:10:32.835180\n",
      "train Loss: 0.1633 Acc: 0.9438\n",
      "val Loss: 0.2957 Acc: 0.8696\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 19:11:12.987300\n",
      "train Loss: 0.1015 Acc: 0.9688\n",
      "val Loss: 0.1435 Acc: 0.9463\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 19:11:53.255580\n",
      "train Loss: 0.0776 Acc: 0.9693\n",
      "val Loss: 0.1848 Acc: 0.9310\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 19:12:33.552945\n",
      "train Loss: 0.0717 Acc: 0.9739\n",
      "val Loss: 0.1445 Acc: 0.9463\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 19:13:13.854748\n",
      "train Loss: 0.0420 Acc: 0.9847\n",
      "val Loss: 0.0636 Acc: 0.9770\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 19:13:54.172037\n",
      "train Loss: 0.0505 Acc: 0.9816\n",
      "val Loss: 0.6382 Acc: 0.9018\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 19:14:34.224305\n",
      "train Loss: 0.0368 Acc: 0.9847\n",
      "val Loss: 0.0753 Acc: 0.9831\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 19:15:14.478709\n",
      "train Loss: 0.0327 Acc: 0.9898\n",
      "val Loss: 0.4709 Acc: 0.8558\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 19:15:54.780985\n",
      "train Loss: 0.0487 Acc: 0.9842\n",
      "val Loss: 0.1404 Acc: 0.9571\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 19:16:35.007975\n",
      "train Loss: 0.0517 Acc: 0.9806\n",
      "val Loss: 0.1597 Acc: 0.9417\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 19:17:15.206426\n",
      "train Loss: 0.0366 Acc: 0.9877\n",
      "val Loss: 0.1576 Acc: 0.9417\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 19:17:55.496544\n",
      "train Loss: 0.0508 Acc: 0.9836\n",
      "val Loss: 0.0870 Acc: 0.9693\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 19:18:35.838699\n",
      "train Loss: 0.0341 Acc: 0.9918\n",
      "val Loss: 0.0908 Acc: 0.9663\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 19:19:16.238811\n",
      "train Loss: 0.0206 Acc: 0.9959\n",
      "val Loss: 0.0562 Acc: 0.9847\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 19:19:56.130493\n",
      "train Loss: 0.0392 Acc: 0.9877\n",
      "val Loss: 0.1683 Acc: 0.9540\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 19:20:36.414518\n",
      "train Loss: 0.0713 Acc: 0.9745\n",
      "val Loss: 0.3436 Acc: 0.9387\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 19:21:16.806068\n",
      "train Loss: 0.0315 Acc: 0.9928\n",
      "val Loss: 0.0612 Acc: 0.9816\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 19:21:57.015978\n",
      "train Loss: 0.0744 Acc: 0.9775\n",
      "val Loss: 0.0935 Acc: 0.9678\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 19:22:37.322881\n",
      "train Loss: 0.0416 Acc: 0.9857\n",
      "val Loss: 0.0621 Acc: 0.9801\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 19:23:17.574932\n",
      "train Loss: 0.0178 Acc: 0.9939\n",
      "val Loss: 0.1042 Acc: 0.9693\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 19:23:57.840102\n",
      "train Loss: 0.0291 Acc: 0.9882\n",
      "val Loss: 0.0493 Acc: 0.9908\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 19:24:38.121592\n",
      "train Loss: 0.0208 Acc: 0.9939\n",
      "val Loss: 0.0485 Acc: 0.9893\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 19:25:18.408795\n",
      "train Loss: 0.0158 Acc: 0.9954\n",
      "val Loss: 0.0430 Acc: 0.9908\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 19:25:58.695154\n",
      "train Loss: 0.0182 Acc: 0.9954\n",
      "val Loss: 0.0590 Acc: 0.9847\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 19:26:39.223100\n",
      "train Loss: 0.0132 Acc: 0.9949\n",
      "val Loss: 0.1660 Acc: 0.9586\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 19:27:19.594546\n",
      "train Loss: 0.0185 Acc: 0.9918\n",
      "val Loss: 0.0802 Acc: 0.9801\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 19:27:59.937196\n",
      "train Loss: 0.0065 Acc: 0.9985\n",
      "val Loss: 0.0512 Acc: 0.9893\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 19:28:40.179169\n",
      "train Loss: 0.0206 Acc: 0.9944\n",
      "val Loss: 0.0809 Acc: 0.9847\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 19:29:20.523702\n",
      "train Loss: 0.0349 Acc: 0.9908\n",
      "val Loss: 0.5833 Acc: 0.8972\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 19:30:00.970746\n",
      "train Loss: 0.0276 Acc: 0.9877\n",
      "val Loss: 0.1205 Acc: 0.9663\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 19:30:40.997060\n",
      "train Loss: 0.0142 Acc: 0.9959\n",
      "val Loss: 0.0442 Acc: 0.9893\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 19:31:21.246835\n",
      "train Loss: 0.0160 Acc: 0.9959\n",
      "val Loss: 0.0265 Acc: 0.9969\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 19:32:01.670929\n",
      "train Loss: 0.0107 Acc: 0.9959\n",
      "val Loss: 0.0369 Acc: 0.9908\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 19:32:42.076889\n",
      "train Loss: 0.0074 Acc: 0.9969\n",
      "val Loss: 0.0573 Acc: 0.9847\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 19:33:22.371077\n",
      "train Loss: 0.0124 Acc: 0.9964\n",
      "val Loss: 0.0221 Acc: 0.9939\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 98 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomVerticalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 19:34:23.089594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1114 Acc: 0.6733\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 19:34:34.187829\n",
      "train Loss: 0.8768 Acc: 0.6801\n",
      "val Loss: 0.8472 Acc: 0.3604\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 19:35:14.319522\n",
      "train Loss: 0.5261 Acc: 0.7649\n",
      "val Loss: 0.7048 Acc: 0.6426\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 19:35:54.695207\n",
      "train Loss: 0.4553 Acc: 0.8038\n",
      "val Loss: 0.5357 Acc: 0.7577\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 19:36:34.969592\n",
      "train Loss: 0.4694 Acc: 0.8135\n",
      "val Loss: 0.4837 Acc: 0.8006\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 19:37:14.900053\n",
      "train Loss: 0.3722 Acc: 0.8380\n",
      "val Loss: 0.3998 Acc: 0.8344\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 19:37:54.922833\n",
      "train Loss: 0.3464 Acc: 0.8559\n",
      "val Loss: 0.9964 Acc: 0.7515\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 19:38:35.317608\n",
      "train Loss: 0.2957 Acc: 0.8794\n",
      "val Loss: 0.3612 Acc: 0.8650\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 19:39:15.468235\n",
      "train Loss: 0.2108 Acc: 0.9162\n",
      "val Loss: 1.6887 Acc: 0.6779\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 19:39:55.694147\n",
      "train Loss: 0.1866 Acc: 0.9336\n",
      "val Loss: 0.6317 Acc: 0.8436\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 19:40:35.708713\n",
      "train Loss: 0.1614 Acc: 0.9453\n",
      "val Loss: 0.2818 Acc: 0.8972\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 19:41:15.978565\n",
      "train Loss: 0.1318 Acc: 0.9530\n",
      "val Loss: 0.8624 Acc: 0.8206\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 19:41:56.154308\n",
      "train Loss: 0.0929 Acc: 0.9658\n",
      "val Loss: 0.3275 Acc: 0.8911\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 19:42:36.467778\n",
      "train Loss: 0.1001 Acc: 0.9658\n",
      "val Loss: 0.1260 Acc: 0.9540\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 19:43:16.723651\n",
      "train Loss: 0.0826 Acc: 0.9673\n",
      "val Loss: 0.1951 Acc: 0.9264\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 19:43:56.849590\n",
      "train Loss: 0.0842 Acc: 0.9714\n",
      "val Loss: 0.1490 Acc: 0.9571\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 19:44:36.887732\n",
      "train Loss: 0.0765 Acc: 0.9755\n",
      "val Loss: 0.3083 Acc: 0.8988\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 19:45:17.118473\n",
      "train Loss: 0.0657 Acc: 0.9734\n",
      "val Loss: 0.1377 Acc: 0.9387\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 19:45:57.412867\n",
      "train Loss: 0.0563 Acc: 0.9826\n",
      "val Loss: 0.1774 Acc: 0.9433\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 19:46:37.804437\n",
      "train Loss: 0.0626 Acc: 0.9775\n",
      "val Loss: 0.8788 Acc: 0.7577\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 19:47:18.917586\n",
      "train Loss: 0.0774 Acc: 0.9785\n",
      "val Loss: 0.4308 Acc: 0.8819\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 19:47:59.772213\n",
      "train Loss: 0.0797 Acc: 0.9709\n",
      "val Loss: 0.2264 Acc: 0.9187\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 19:48:40.540885\n",
      "train Loss: 0.0488 Acc: 0.9831\n",
      "val Loss: 0.1287 Acc: 0.9555\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 19:49:21.478547\n",
      "train Loss: 0.0312 Acc: 0.9842\n",
      "val Loss: 0.0845 Acc: 0.9785\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 19:50:02.580406\n",
      "train Loss: 0.0390 Acc: 0.9867\n",
      "val Loss: 0.2088 Acc: 0.9494\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 19:50:43.382684\n",
      "train Loss: 0.0420 Acc: 0.9842\n",
      "val Loss: 0.1174 Acc: 0.9724\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 19:51:24.027907\n",
      "train Loss: 0.0548 Acc: 0.9816\n",
      "val Loss: 0.1925 Acc: 0.9417\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 19:52:04.909069\n",
      "train Loss: 0.0556 Acc: 0.9806\n",
      "val Loss: 0.1248 Acc: 0.9647\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 19:52:45.580196\n",
      "train Loss: 0.0311 Acc: 0.9898\n",
      "val Loss: 0.0862 Acc: 0.9801\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 19:53:26.034700\n",
      "train Loss: 0.0393 Acc: 0.9826\n",
      "val Loss: 0.2778 Acc: 0.8773\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 19:54:06.602612\n",
      "train Loss: 0.0218 Acc: 0.9908\n",
      "val Loss: 0.1476 Acc: 0.9632\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 19:54:47.188046\n",
      "train Loss: 0.0139 Acc: 0.9928\n",
      "val Loss: 0.0829 Acc: 0.9801\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 19:55:28.317876\n",
      "train Loss: 0.0299 Acc: 0.9908\n",
      "val Loss: 0.1266 Acc: 0.9509\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 19:56:09.306662\n",
      "train Loss: 0.0269 Acc: 0.9908\n",
      "val Loss: 0.1211 Acc: 0.9663\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 19:56:50.022327\n",
      "train Loss: 0.0217 Acc: 0.9918\n",
      "val Loss: 0.0935 Acc: 0.9785\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 19:57:31.712988\n",
      "train Loss: 0.0178 Acc: 0.9934\n",
      "val Loss: 0.1036 Acc: 0.9739\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 19:58:13.083836\n",
      "train Loss: 0.0218 Acc: 0.9954\n",
      "val Loss: 0.0978 Acc: 0.9739\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 19:58:53.815663\n",
      "train Loss: 0.0342 Acc: 0.9877\n",
      "val Loss: 0.0770 Acc: 0.9709\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 19:59:34.787353\n",
      "train Loss: 0.0298 Acc: 0.9898\n",
      "val Loss: 0.1646 Acc: 0.9586\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 20:00:15.621806\n",
      "train Loss: 0.0117 Acc: 0.9959\n",
      "val Loss: 0.1373 Acc: 0.9724\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 20:00:56.438190\n",
      "train Loss: 0.0192 Acc: 0.9954\n",
      "val Loss: 0.2078 Acc: 0.9433\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 20:01:37.216892\n",
      "train Loss: 0.0188 Acc: 0.9918\n",
      "val Loss: 0.1963 Acc: 0.9463\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 20:02:17.730640\n",
      "train Loss: 0.0389 Acc: 0.9923\n",
      "val Loss: 0.0878 Acc: 0.9678\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 20:02:58.109721\n",
      "train Loss: 0.0258 Acc: 0.9918\n",
      "val Loss: 0.1045 Acc: 0.9801\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 20:03:38.678243\n",
      "train Loss: 0.0190 Acc: 0.9959\n",
      "val Loss: 0.0626 Acc: 0.9877\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 20:04:19.217592\n",
      "train Loss: 0.0149 Acc: 0.9954\n",
      "val Loss: 0.1192 Acc: 0.9739\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 20:04:59.715820\n",
      "train Loss: 0.0168 Acc: 0.9934\n",
      "val Loss: 0.0853 Acc: 0.9739\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 20:05:40.209311\n",
      "train Loss: 0.0302 Acc: 0.9898\n",
      "val Loss: 0.0901 Acc: 0.9724\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 20:06:20.673788\n",
      "train Loss: 0.0266 Acc: 0.9908\n",
      "val Loss: 0.0651 Acc: 0.9862\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 20:07:01.373608\n",
      "train Loss: 0.0223 Acc: 0.9923\n",
      "val Loss: 0.0882 Acc: 0.9877\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 98 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomRotation(degrees=(-180, 180), resample=False, expand=False)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 20:08:02.479630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9175 Acc: 0.6733\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 20:08:13.646357\n",
      "train Loss: 0.8245 Acc: 0.6796\n",
      "val Loss: 0.6581 Acc: 0.6718\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 20:08:54.297261\n",
      "train Loss: 0.5465 Acc: 0.7466\n",
      "val Loss: 0.8929 Acc: 0.5951\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 20:09:34.755735\n",
      "train Loss: 0.4796 Acc: 0.7925\n",
      "val Loss: 0.9456 Acc: 0.6610\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 20:10:15.353128\n",
      "train Loss: 0.4837 Acc: 0.7823\n",
      "val Loss: 0.4895 Acc: 0.7653\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 20:10:55.919872\n",
      "train Loss: 0.4715 Acc: 0.7946\n",
      "val Loss: 0.4796 Acc: 0.7837\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 20:11:36.484641\n",
      "train Loss: 0.4697 Acc: 0.7946\n",
      "val Loss: 0.5006 Acc: 0.7699\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 20:12:17.085900\n",
      "train Loss: 0.4629 Acc: 0.7936\n",
      "val Loss: 0.5335 Acc: 0.7776\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 20:12:57.664741\n",
      "train Loss: 0.4728 Acc: 0.7910\n",
      "val Loss: 0.5174 Acc: 0.7684\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 20:13:38.198696\n",
      "train Loss: 0.4399 Acc: 0.8002\n",
      "val Loss: 0.5026 Acc: 0.7745\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 20:14:18.580705\n",
      "train Loss: 0.4416 Acc: 0.8099\n",
      "val Loss: 0.4753 Acc: 0.7975\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 20:14:58.846952\n",
      "train Loss: 0.4219 Acc: 0.8150\n",
      "val Loss: 0.4953 Acc: 0.7853\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 20:15:39.325646\n",
      "train Loss: 0.4349 Acc: 0.8104\n",
      "val Loss: 0.5716 Acc: 0.7653\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 20:16:19.715853\n",
      "train Loss: 0.4419 Acc: 0.8176\n",
      "val Loss: 0.5464 Acc: 0.7669\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 20:17:00.194415\n",
      "train Loss: 0.4170 Acc: 0.8304\n",
      "val Loss: 0.4880 Acc: 0.7914\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 20:17:40.697679\n",
      "train Loss: 0.4279 Acc: 0.8176\n",
      "val Loss: 0.4963 Acc: 0.7699\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 20:18:21.052995\n",
      "train Loss: 0.4171 Acc: 0.8217\n",
      "val Loss: 0.4638 Acc: 0.8037\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 20:19:01.624523\n",
      "train Loss: 0.4072 Acc: 0.8319\n",
      "val Loss: 0.4872 Acc: 0.7868\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 20:19:41.991035\n",
      "train Loss: 0.4063 Acc: 0.8314\n",
      "val Loss: 0.6582 Acc: 0.6304\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 20:20:22.426100\n",
      "train Loss: 0.4599 Acc: 0.8043\n",
      "val Loss: 0.4523 Acc: 0.8144\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 20:21:02.791480\n",
      "train Loss: 0.4184 Acc: 0.8227\n",
      "val Loss: 0.4743 Acc: 0.8006\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 20:21:42.921233\n",
      "train Loss: 0.3840 Acc: 0.8370\n",
      "val Loss: 0.5840 Acc: 0.7561\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 20:22:23.409553\n",
      "train Loss: 0.3940 Acc: 0.8436\n",
      "val Loss: 0.5265 Acc: 0.7515\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 20:23:03.852911\n",
      "train Loss: 0.3896 Acc: 0.8339\n",
      "val Loss: 0.4098 Acc: 0.8298\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 20:23:44.232173\n",
      "train Loss: 0.3830 Acc: 0.8421\n",
      "val Loss: 0.7031 Acc: 0.6258\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 20:24:24.616287\n",
      "train Loss: 0.3964 Acc: 0.8390\n",
      "val Loss: 0.7676 Acc: 0.7285\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 20:25:05.300648\n",
      "train Loss: 0.3907 Acc: 0.8350\n",
      "val Loss: 0.5158 Acc: 0.7653\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 20:25:45.718013\n",
      "train Loss: 0.3817 Acc: 0.8411\n",
      "val Loss: 0.7259 Acc: 0.7485\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 20:26:26.010110\n",
      "train Loss: 0.3943 Acc: 0.8396\n",
      "val Loss: 0.5355 Acc: 0.7546\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 20:27:06.278766\n",
      "train Loss: 0.3554 Acc: 0.8472\n",
      "val Loss: 0.4551 Acc: 0.8098\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 20:27:46.654936\n",
      "train Loss: 0.3170 Acc: 0.8845\n",
      "val Loss: 0.4459 Acc: 0.8252\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 20:28:27.175645\n",
      "train Loss: 0.3230 Acc: 0.8666\n",
      "val Loss: 0.3440 Acc: 0.8742\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 20:29:07.802414\n",
      "train Loss: 0.3063 Acc: 0.8763\n",
      "val Loss: 0.4956 Acc: 0.8129\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 20:29:48.196031\n",
      "train Loss: 0.3100 Acc: 0.8855\n",
      "val Loss: 0.7125 Acc: 0.6963\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 20:30:28.698231\n",
      "train Loss: 0.3100 Acc: 0.8835\n",
      "val Loss: 0.4334 Acc: 0.8021\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 20:31:09.143293\n",
      "train Loss: 0.3132 Acc: 0.8687\n",
      "val Loss: 0.6724 Acc: 0.7991\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 20:31:49.714659\n",
      "train Loss: 0.3019 Acc: 0.8825\n",
      "val Loss: 0.4948 Acc: 0.7761\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 20:32:30.109046\n",
      "train Loss: 0.3056 Acc: 0.8901\n",
      "val Loss: 0.2928 Acc: 0.8880\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 20:33:10.351688\n",
      "train Loss: 0.2764 Acc: 0.8901\n",
      "val Loss: 0.4130 Acc: 0.8344\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 20:33:50.847883\n",
      "train Loss: 0.3005 Acc: 0.8804\n",
      "val Loss: 0.3394 Acc: 0.8666\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 20:34:31.185605\n",
      "train Loss: 0.2623 Acc: 0.8942\n",
      "val Loss: 0.4080 Acc: 0.8635\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 20:35:11.614508\n",
      "train Loss: 0.3249 Acc: 0.8677\n",
      "val Loss: 0.3717 Acc: 0.8282\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 20:35:52.028735\n",
      "train Loss: 0.2629 Acc: 0.8912\n",
      "val Loss: 0.2523 Acc: 0.9080\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 20:36:32.822664\n",
      "train Loss: 0.2452 Acc: 0.9080\n",
      "val Loss: 0.3437 Acc: 0.8574\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 20:37:13.285661\n",
      "train Loss: 0.2287 Acc: 0.9152\n",
      "val Loss: 0.2422 Acc: 0.8926\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 20:37:53.792120\n",
      "train Loss: 0.2217 Acc: 0.9090\n",
      "val Loss: 0.3049 Acc: 0.9003\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 20:38:34.295260\n",
      "train Loss: 0.2246 Acc: 0.9085\n",
      "val Loss: 0.2557 Acc: 0.8988\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 20:39:14.801682\n",
      "train Loss: 0.2249 Acc: 0.9106\n",
      "val Loss: 0.4230 Acc: 0.8052\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 20:39:55.329544\n",
      "train Loss: 0.2352 Acc: 0.9080\n",
      "val Loss: 0.4647 Acc: 0.7929\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 20:40:35.815176\n",
      "train Loss: 0.2216 Acc: 0.9142\n",
      "val Loss: 0.2290 Acc: 0.9095\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 90 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomPerspective(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 20:41:36.651089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.5051 Acc: 0.6733\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 20:41:47.725107\n",
      "train Loss: 0.9166 Acc: 0.6755\n",
      "val Loss: 0.5928 Acc: 0.7025\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 20:42:29.477454\n",
      "train Loss: 0.5089 Acc: 0.7557\n",
      "val Loss: 1.0122 Acc: 0.6503\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 20:43:11.015927\n",
      "train Loss: 0.4921 Acc: 0.7721\n",
      "val Loss: 1.0458 Acc: 0.6273\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 20:43:52.322560\n",
      "train Loss: 0.4672 Acc: 0.8022\n",
      "val Loss: 0.9101 Acc: 0.6933\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 20:44:33.761280\n",
      "train Loss: 0.4676 Acc: 0.8002\n",
      "val Loss: 0.5200 Acc: 0.7745\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 20:45:15.296968\n",
      "train Loss: 0.4524 Acc: 0.7966\n",
      "val Loss: 0.4665 Acc: 0.7929\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 20:45:56.677025\n",
      "train Loss: 0.3985 Acc: 0.8247\n",
      "val Loss: 0.6045 Acc: 0.7025\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 20:46:38.123082\n",
      "train Loss: 0.3756 Acc: 0.8636\n",
      "val Loss: 0.4783 Acc: 0.8313\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 20:47:19.614053\n",
      "train Loss: 0.3735 Acc: 0.8462\n",
      "val Loss: 0.5626 Acc: 0.8543\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 20:48:00.975242\n",
      "train Loss: 0.3128 Acc: 0.8820\n",
      "val Loss: 0.9693 Acc: 0.8666\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 20:48:42.522858\n",
      "train Loss: 0.2943 Acc: 0.8753\n",
      "val Loss: 0.7094 Acc: 0.8650\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 20:49:24.050999\n",
      "train Loss: 0.2296 Acc: 0.9131\n",
      "val Loss: 0.6265 Acc: 0.7929\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 20:50:05.514281\n",
      "train Loss: 0.2229 Acc: 0.9126\n",
      "val Loss: 0.4074 Acc: 0.7715\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 20:50:47.102006\n",
      "train Loss: 0.1791 Acc: 0.9392\n",
      "val Loss: 1.0661 Acc: 0.5798\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 20:51:28.714474\n",
      "train Loss: 0.1954 Acc: 0.9198\n",
      "val Loss: 0.8613 Acc: 0.8313\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 20:52:10.079064\n",
      "train Loss: 0.1416 Acc: 0.9504\n",
      "val Loss: 0.3229 Acc: 0.8620\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 20:52:51.510427\n",
      "train Loss: 0.1510 Acc: 0.9433\n",
      "val Loss: 0.2197 Acc: 0.9049\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 20:53:32.996057\n",
      "train Loss: 0.1113 Acc: 0.9591\n",
      "val Loss: 0.1634 Acc: 0.9448\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 20:54:14.487614\n",
      "train Loss: 0.0844 Acc: 0.9729\n",
      "val Loss: 0.1179 Acc: 0.9586\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 20:54:55.959525\n",
      "train Loss: 0.0745 Acc: 0.9745\n",
      "val Loss: 0.0433 Acc: 0.9847\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 20:55:37.395463\n",
      "train Loss: 0.0652 Acc: 0.9796\n",
      "val Loss: 0.0556 Acc: 0.9877\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 20:56:18.929815\n",
      "train Loss: 0.0519 Acc: 0.9826\n",
      "val Loss: 0.0184 Acc: 0.9954\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 20:57:00.384494\n",
      "train Loss: 0.0590 Acc: 0.9847\n",
      "val Loss: 0.0209 Acc: 0.9954\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 20:57:41.672982\n",
      "train Loss: 0.0634 Acc: 0.9790\n",
      "val Loss: 0.1930 Acc: 0.9172\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 20:58:24.522911\n",
      "train Loss: 0.0443 Acc: 0.9842\n",
      "val Loss: 0.1271 Acc: 0.9540\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 20:59:05.964454\n",
      "train Loss: 0.0354 Acc: 0.9893\n",
      "val Loss: 0.0309 Acc: 0.9923\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 20:59:47.229517\n",
      "train Loss: 0.0612 Acc: 0.9801\n",
      "val Loss: 0.8790 Acc: 0.9049\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 21:00:28.639268\n",
      "train Loss: 0.0719 Acc: 0.9739\n",
      "val Loss: 0.5545 Acc: 0.9387\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 21:01:10.146669\n",
      "train Loss: 0.0793 Acc: 0.9683\n",
      "val Loss: 0.1119 Acc: 0.9632\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 21:01:51.630199\n",
      "train Loss: 0.0604 Acc: 0.9836\n",
      "val Loss: 0.3559 Acc: 0.9402\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 21:02:33.134289\n",
      "train Loss: 0.0333 Acc: 0.9893\n",
      "val Loss: 0.0994 Acc: 0.9571\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 21:03:14.553666\n",
      "train Loss: 0.0286 Acc: 0.9918\n",
      "val Loss: 0.0361 Acc: 0.9908\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 21:03:56.189561\n",
      "train Loss: 0.0279 Acc: 0.9908\n",
      "val Loss: 0.0037 Acc: 1.0000\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 21:04:37.548262\n",
      "train Loss: 0.0278 Acc: 0.9923\n",
      "val Loss: 0.0297 Acc: 0.9923\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 21:05:18.929789\n",
      "train Loss: 0.0265 Acc: 0.9923\n",
      "val Loss: 0.0241 Acc: 0.9939\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 21:06:00.349942\n",
      "train Loss: 0.0397 Acc: 0.9852\n",
      "val Loss: 0.0252 Acc: 0.9877\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 21:06:41.771730\n",
      "train Loss: 0.0306 Acc: 0.9908\n",
      "val Loss: 0.0302 Acc: 0.9923\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 21:07:23.473165\n",
      "train Loss: 0.0320 Acc: 0.9903\n",
      "val Loss: 0.0511 Acc: 0.9877\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 21:08:04.814820\n",
      "train Loss: 0.1211 Acc: 0.9601\n",
      "val Loss: 0.0813 Acc: 0.9755\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 21:08:46.255305\n",
      "train Loss: 0.0578 Acc: 0.9811\n",
      "val Loss: 0.0566 Acc: 0.9847\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 21:09:27.739973\n",
      "train Loss: 0.0419 Acc: 0.9877\n",
      "val Loss: 0.0432 Acc: 0.9862\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 21:10:09.178114\n",
      "train Loss: 0.0452 Acc: 0.9862\n",
      "val Loss: 0.0384 Acc: 0.9862\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 21:10:50.646642\n",
      "train Loss: 0.0320 Acc: 0.9903\n",
      "val Loss: 0.0587 Acc: 0.9801\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 21:11:31.837605\n",
      "train Loss: 0.0310 Acc: 0.9928\n",
      "val Loss: 0.0764 Acc: 0.9801\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 21:12:13.378073\n",
      "train Loss: 0.0209 Acc: 0.9949\n",
      "val Loss: 0.0280 Acc: 0.9954\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 21:12:54.995538\n",
      "train Loss: 0.0560 Acc: 0.9847\n",
      "val Loss: 0.1607 Acc: 0.9340\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 21:13:36.265346\n",
      "train Loss: 0.0582 Acc: 0.9770\n",
      "val Loss: 0.4519 Acc: 0.6794\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 21:14:17.742341\n",
      "train Loss: 0.0451 Acc: 0.9852\n",
      "val Loss: 0.4682 Acc: 0.8604\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 21:14:59.177003\n",
      "train Loss: 0.0388 Acc: 0.9877\n",
      "val Loss: 0.0704 Acc: 0.9647\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 96 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 21:16:01.782927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6243 Acc: 0.6748\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 21:16:12.894095\n",
      "train Loss: 0.9194 Acc: 0.6648\n",
      "val Loss: 0.7899 Acc: 0.6779\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 21:16:53.809156\n",
      "train Loss: 0.5529 Acc: 0.7409\n",
      "val Loss: 0.6389 Acc: 0.7101\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 21:17:34.667337\n",
      "train Loss: 0.5124 Acc: 0.7752\n",
      "val Loss: 0.5142 Acc: 0.7684\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 21:18:15.360876\n",
      "train Loss: 0.5104 Acc: 0.7680\n",
      "val Loss: 0.5140 Acc: 0.7745\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 21:18:56.258107\n",
      "train Loss: 0.4778 Acc: 0.7920\n",
      "val Loss: 0.4823 Acc: 0.7761\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 21:19:37.122168\n",
      "train Loss: 0.4838 Acc: 0.7885\n",
      "val Loss: 0.5484 Acc: 0.7669\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 21:20:17.858519\n",
      "train Loss: 0.4967 Acc: 0.7701\n",
      "val Loss: 0.6884 Acc: 0.6948\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 21:20:58.837853\n",
      "train Loss: 0.4757 Acc: 0.7885\n",
      "val Loss: 0.5446 Acc: 0.7500\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 21:21:39.616552\n",
      "train Loss: 0.4365 Acc: 0.8166\n",
      "val Loss: 0.5565 Acc: 0.7055\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 21:22:20.386086\n",
      "train Loss: 0.4381 Acc: 0.8166\n",
      "val Loss: 0.4376 Acc: 0.8083\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 21:23:01.095783\n",
      "train Loss: 0.4330 Acc: 0.8160\n",
      "val Loss: 1.1668 Acc: 0.6902\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 21:23:41.986866\n",
      "train Loss: 0.4483 Acc: 0.8038\n",
      "val Loss: 0.3657 Acc: 0.8620\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 21:24:22.644266\n",
      "train Loss: 0.4115 Acc: 0.8191\n",
      "val Loss: 0.4319 Acc: 0.8175\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 21:25:03.705794\n",
      "train Loss: 0.4018 Acc: 0.8385\n",
      "val Loss: 0.4230 Acc: 0.8359\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 21:25:44.653028\n",
      "train Loss: 0.3867 Acc: 0.8411\n",
      "val Loss: 0.3368 Acc: 0.8972\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 21:26:25.389592\n",
      "train Loss: 0.3545 Acc: 0.8564\n",
      "val Loss: 0.4218 Acc: 0.8436\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 21:27:06.428465\n",
      "train Loss: 0.3964 Acc: 0.8421\n",
      "val Loss: 0.5420 Acc: 0.8129\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 21:27:47.381971\n",
      "train Loss: 0.3396 Acc: 0.8646\n",
      "val Loss: 0.9356 Acc: 0.6963\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 21:28:27.964290\n",
      "train Loss: 0.3401 Acc: 0.8631\n",
      "val Loss: 0.5175 Acc: 0.8221\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 21:29:08.818349\n",
      "train Loss: 0.2956 Acc: 0.8815\n",
      "val Loss: 0.2914 Acc: 0.9064\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 21:29:49.478655\n",
      "train Loss: 0.2971 Acc: 0.8861\n",
      "val Loss: 0.9471 Acc: 0.8712\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 21:30:30.329873\n",
      "train Loss: 0.3349 Acc: 0.8636\n",
      "val Loss: 1.0321 Acc: 0.7960\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 21:31:11.182993\n",
      "train Loss: 0.3027 Acc: 0.8820\n",
      "val Loss: 0.5024 Acc: 0.8252\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 21:31:51.882152\n",
      "train Loss: 0.3029 Acc: 0.8830\n",
      "val Loss: 1.3396 Acc: 0.8497\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 21:32:32.817721\n",
      "train Loss: 0.2867 Acc: 0.8840\n",
      "val Loss: 0.3380 Acc: 0.9080\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 21:33:13.896126\n",
      "train Loss: 0.2874 Acc: 0.8947\n",
      "val Loss: 0.3296 Acc: 0.8666\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 21:33:54.776823\n",
      "train Loss: 0.2710 Acc: 0.9014\n",
      "val Loss: 0.3234 Acc: 0.9126\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 21:34:36.078981\n",
      "train Loss: 0.2346 Acc: 0.9085\n",
      "val Loss: 0.1125 Acc: 0.9571\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 21:35:17.184243\n",
      "train Loss: 0.2683 Acc: 0.8901\n",
      "val Loss: 0.5790 Acc: 0.8957\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 21:35:58.183054\n",
      "train Loss: 0.2588 Acc: 0.8947\n",
      "val Loss: 0.4931 Acc: 0.8896\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 21:36:39.193161\n",
      "train Loss: 0.2577 Acc: 0.8968\n",
      "val Loss: 0.1515 Acc: 0.9647\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 21:37:20.165882\n",
      "train Loss: 0.2914 Acc: 0.8876\n",
      "val Loss: 0.3843 Acc: 0.8635\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 21:38:01.049874\n",
      "train Loss: 0.2470 Acc: 0.9044\n",
      "val Loss: 0.9648 Acc: 0.8773\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 21:38:41.884775\n",
      "train Loss: 0.2519 Acc: 0.9024\n",
      "val Loss: 0.5017 Acc: 0.8727\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 21:39:22.890084\n",
      "train Loss: 0.2338 Acc: 0.9177\n",
      "val Loss: 0.1406 Acc: 0.9463\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 21:40:04.040474\n",
      "train Loss: 0.2185 Acc: 0.9111\n",
      "val Loss: 0.1564 Acc: 0.9202\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 21:40:45.110460\n",
      "train Loss: 0.2782 Acc: 0.8917\n",
      "val Loss: 0.1051 Acc: 0.9739\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 21:41:26.021990\n",
      "train Loss: 0.2322 Acc: 0.9080\n",
      "val Loss: 0.0839 Acc: 0.9739\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 21:42:06.992970\n",
      "train Loss: 0.2035 Acc: 0.9208\n",
      "val Loss: 0.2720 Acc: 0.8926\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 21:42:47.807985\n",
      "train Loss: 0.1957 Acc: 0.9193\n",
      "val Loss: 0.2808 Acc: 0.9049\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 21:43:28.799496\n",
      "train Loss: 0.2385 Acc: 0.9111\n",
      "val Loss: 0.0856 Acc: 0.9755\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 21:44:09.768324\n",
      "train Loss: 0.1991 Acc: 0.9198\n",
      "val Loss: 0.1113 Acc: 0.9816\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 21:44:50.612858\n",
      "train Loss: 0.1926 Acc: 0.9274\n",
      "val Loss: 0.1935 Acc: 0.9141\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 21:45:31.671717\n",
      "train Loss: 0.2357 Acc: 0.9014\n",
      "val Loss: 0.0755 Acc: 0.9770\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 21:46:12.694595\n",
      "train Loss: 0.1977 Acc: 0.9208\n",
      "val Loss: 0.0972 Acc: 0.9601\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 21:46:53.704573\n",
      "train Loss: 0.2083 Acc: 0.9228\n",
      "val Loss: 0.1019 Acc: 0.9555\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 21:47:34.602661\n",
      "train Loss: 0.1754 Acc: 0.9336\n",
      "val Loss: 0.0696 Acc: 0.9785\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 21:48:15.475553\n",
      "train Loss: 0.1925 Acc: 0.9274\n",
      "val Loss: 0.0608 Acc: 0.9801\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 21:48:56.157419\n",
      "train Loss: 0.1904 Acc: 0.9280\n",
      "val Loss: 0.0944 Acc: 0.9632\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 95 %\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    <torchvision.transforms.transforms.RandomErasing object at 0x7f5603813320>\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 21:49:57.412170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 10.1641 Acc: 0.3267\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 21:50:08.580312\n",
      "train Loss: 1.1348 Acc: 0.6280\n",
      "val Loss: 0.6214 Acc: 0.6702\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 21:50:49.262621\n",
      "train Loss: 0.5306 Acc: 0.7660\n",
      "val Loss: 0.5408 Acc: 0.7669\n",
      "----------\n",
      "Epoch 4/50 2020-04-04 21:51:29.962728\n",
      "train Loss: 0.5520 Acc: 0.7481\n",
      "val Loss: 0.5472 Acc: 0.7745\n",
      "----------\n",
      "Epoch 5/50 2020-04-04 21:52:10.292715\n",
      "train Loss: 0.4808 Acc: 0.7879\n",
      "val Loss: 0.6470 Acc: 0.7071\n",
      "----------\n",
      "Epoch 6/50 2020-04-04 21:52:50.626345\n",
      "train Loss: 0.4881 Acc: 0.7874\n",
      "val Loss: 0.5009 Acc: 0.7975\n",
      "----------\n",
      "Epoch 7/50 2020-04-04 21:53:31.005572\n",
      "train Loss: 0.5044 Acc: 0.7803\n",
      "val Loss: 0.4804 Acc: 0.7899\n",
      "----------\n",
      "Epoch 8/50 2020-04-04 21:54:11.787982\n",
      "train Loss: 0.4511 Acc: 0.8017\n",
      "val Loss: 0.4420 Acc: 0.8083\n",
      "----------\n",
      "Epoch 9/50 2020-04-04 21:54:52.216388\n",
      "train Loss: 0.4528 Acc: 0.8053\n",
      "val Loss: 0.5207 Acc: 0.7960\n",
      "----------\n",
      "Epoch 10/50 2020-04-04 21:55:33.102668\n",
      "train Loss: 0.4456 Acc: 0.8079\n",
      "val Loss: 0.5527 Acc: 0.7929\n",
      "----------\n",
      "Epoch 11/50 2020-04-04 21:56:14.040039\n",
      "train Loss: 0.4169 Acc: 0.8263\n",
      "val Loss: 0.5942 Acc: 0.7485\n",
      "----------\n",
      "Epoch 12/50 2020-04-04 21:56:54.561008\n",
      "train Loss: 0.4194 Acc: 0.8324\n",
      "val Loss: 1.5831 Acc: 0.7439\n",
      "----------\n",
      "Epoch 13/50 2020-04-04 21:57:35.202557\n",
      "train Loss: 0.4134 Acc: 0.8283\n",
      "val Loss: 0.3890 Acc: 0.8589\n",
      "----------\n",
      "Epoch 14/50 2020-04-04 21:58:15.883634\n",
      "train Loss: 0.3493 Acc: 0.8620\n",
      "val Loss: 0.3798 Acc: 0.8466\n",
      "----------\n",
      "Epoch 15/50 2020-04-04 21:58:56.563016\n",
      "train Loss: 0.2972 Acc: 0.8799\n",
      "val Loss: 0.4120 Acc: 0.8344\n",
      "----------\n",
      "Epoch 16/50 2020-04-04 21:59:37.256729\n",
      "train Loss: 0.2640 Acc: 0.8958\n",
      "val Loss: 0.8257 Acc: 0.8942\n",
      "----------\n",
      "Epoch 17/50 2020-04-04 22:00:17.880029\n",
      "train Loss: 0.2712 Acc: 0.8927\n",
      "val Loss: 0.1967 Acc: 0.9218\n",
      "----------\n",
      "Epoch 18/50 2020-04-04 22:00:58.316321\n",
      "train Loss: 0.2454 Acc: 0.8963\n",
      "val Loss: 0.1448 Acc: 0.9402\n",
      "----------\n",
      "Epoch 19/50 2020-04-04 22:01:38.827649\n",
      "train Loss: 0.1951 Acc: 0.9157\n",
      "val Loss: 0.2128 Acc: 0.9233\n",
      "----------\n",
      "Epoch 20/50 2020-04-04 22:02:19.199390\n",
      "train Loss: 0.1637 Acc: 0.9331\n",
      "val Loss: 0.2600 Acc: 0.9110\n",
      "----------\n",
      "Epoch 21/50 2020-04-04 22:02:59.725985\n",
      "train Loss: 0.1455 Acc: 0.9515\n",
      "val Loss: 0.0435 Acc: 0.9862\n",
      "----------\n",
      "Epoch 22/50 2020-04-04 22:03:40.277597\n",
      "train Loss: 0.1257 Acc: 0.9555\n",
      "val Loss: 0.0707 Acc: 0.9770\n",
      "----------\n",
      "Epoch 23/50 2020-04-04 22:04:20.786797\n",
      "train Loss: 0.1154 Acc: 0.9617\n",
      "val Loss: 0.0346 Acc: 0.9877\n",
      "----------\n",
      "Epoch 24/50 2020-04-04 22:05:01.161370\n",
      "train Loss: 0.0914 Acc: 0.9688\n",
      "val Loss: 0.0464 Acc: 0.9816\n",
      "----------\n",
      "Epoch 25/50 2020-04-04 22:05:41.771830\n",
      "train Loss: 0.0883 Acc: 0.9632\n",
      "val Loss: 0.0183 Acc: 0.9939\n",
      "----------\n",
      "Epoch 26/50 2020-04-04 22:06:22.322004\n",
      "train Loss: 0.0867 Acc: 0.9663\n",
      "val Loss: 0.2017 Acc: 0.9095\n",
      "----------\n",
      "Epoch 27/50 2020-04-04 22:07:02.946930\n",
      "train Loss: 0.0779 Acc: 0.9663\n",
      "val Loss: 0.0744 Acc: 0.9693\n",
      "----------\n",
      "Epoch 28/50 2020-04-04 22:07:43.600026\n",
      "train Loss: 0.1019 Acc: 0.9617\n",
      "val Loss: 0.0297 Acc: 0.9893\n",
      "----------\n",
      "Epoch 29/50 2020-04-04 22:08:24.182283\n",
      "train Loss: 0.0683 Acc: 0.9755\n",
      "val Loss: 0.0475 Acc: 0.9831\n",
      "----------\n",
      "Epoch 30/50 2020-04-04 22:09:04.840491\n",
      "train Loss: 0.0553 Acc: 0.9811\n",
      "val Loss: 0.0699 Acc: 0.9801\n",
      "----------\n",
      "Epoch 31/50 2020-04-04 22:09:45.222989\n",
      "train Loss: 0.0901 Acc: 0.9699\n",
      "val Loss: 0.0515 Acc: 0.9862\n",
      "----------\n",
      "Epoch 32/50 2020-04-04 22:10:25.867582\n",
      "train Loss: 0.0727 Acc: 0.9729\n",
      "val Loss: 0.0220 Acc: 0.9893\n",
      "----------\n",
      "Epoch 33/50 2020-04-04 22:11:06.487331\n",
      "train Loss: 0.0610 Acc: 0.9734\n",
      "val Loss: 0.0281 Acc: 0.9939\n",
      "----------\n",
      "Epoch 34/50 2020-04-04 22:11:47.276721\n",
      "train Loss: 0.0596 Acc: 0.9811\n",
      "val Loss: 0.0154 Acc: 0.9969\n",
      "----------\n",
      "Epoch 35/50 2020-04-04 22:12:27.807730\n",
      "train Loss: 0.0500 Acc: 0.9816\n",
      "val Loss: 0.0262 Acc: 0.9908\n",
      "----------\n",
      "Epoch 36/50 2020-04-04 22:13:08.545635\n",
      "train Loss: 0.0438 Acc: 0.9872\n",
      "val Loss: 0.0890 Acc: 0.9724\n",
      "----------\n",
      "Epoch 37/50 2020-04-04 22:13:49.167248\n",
      "train Loss: 0.0499 Acc: 0.9821\n",
      "val Loss: 0.0276 Acc: 0.9923\n",
      "----------\n",
      "Epoch 38/50 2020-04-04 22:14:29.744287\n",
      "train Loss: 0.0480 Acc: 0.9816\n",
      "val Loss: 0.0409 Acc: 0.9908\n",
      "----------\n",
      "Epoch 39/50 2020-04-04 22:15:10.351376\n",
      "train Loss: 0.0801 Acc: 0.9678\n",
      "val Loss: 0.0856 Acc: 0.9724\n",
      "----------\n",
      "Epoch 40/50 2020-04-04 22:15:50.998949\n",
      "train Loss: 0.0793 Acc: 0.9668\n",
      "val Loss: 0.0445 Acc: 0.9893\n",
      "----------\n",
      "Epoch 41/50 2020-04-04 22:16:31.716269\n",
      "train Loss: 0.0669 Acc: 0.9750\n",
      "val Loss: 0.4585 Acc: 0.8113\n",
      "----------\n",
      "Epoch 42/50 2020-04-04 22:17:12.291543\n",
      "train Loss: 0.0755 Acc: 0.9739\n",
      "val Loss: 0.1416 Acc: 0.9509\n",
      "----------\n",
      "Epoch 43/50 2020-04-04 22:17:52.899966\n",
      "train Loss: 0.0545 Acc: 0.9836\n",
      "val Loss: 0.0339 Acc: 0.9908\n",
      "----------\n",
      "Epoch 44/50 2020-04-04 22:18:33.469754\n",
      "train Loss: 0.0862 Acc: 0.9704\n",
      "val Loss: 0.0474 Acc: 0.9816\n",
      "----------\n",
      "Epoch 45/50 2020-04-04 22:19:14.197707\n",
      "train Loss: 0.0367 Acc: 0.9888\n",
      "val Loss: 0.0261 Acc: 0.9908\n",
      "----------\n",
      "Epoch 46/50 2020-04-04 22:19:54.842859\n",
      "train Loss: 0.0543 Acc: 0.9811\n",
      "val Loss: 0.0416 Acc: 0.9862\n",
      "----------\n",
      "Epoch 47/50 2020-04-04 22:20:35.441795\n",
      "train Loss: 0.0396 Acc: 0.9862\n",
      "val Loss: 0.0321 Acc: 0.9939\n",
      "----------\n",
      "Epoch 48/50 2020-04-04 22:21:15.976692\n",
      "train Loss: 0.0605 Acc: 0.9801\n",
      "val Loss: 0.0942 Acc: 0.9709\n",
      "----------\n",
      "Epoch 49/50 2020-04-04 22:21:56.594585\n",
      "train Loss: 0.0560 Acc: 0.9765\n",
      "val Loss: 0.1028 Acc: 0.9555\n",
      "----------\n",
      "Epoch 50/50 2020-04-04 22:22:37.541485\n",
      "train Loss: 0.0421 Acc: 0.9857\n",
      "val Loss: 0.1395 Acc: 0.9663\n",
      "Finished Training\n",
      "検証画像に対しての正解率： 95 %\n",
      "乱数シード=2\n",
      "transform=Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "cuda\n",
      "multiGPU\n",
      "----------\n",
      "Epoch 1/50 2020-04-04 22:23:38.693105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.5034 Acc: 0.6733\n",
      "----------\n",
      "Epoch 2/50 2020-04-04 22:23:49.924659\n",
      "train Loss: 0.9804 Acc: 0.6704\n",
      "val Loss: 0.6640 Acc: 0.6242\n",
      "----------\n",
      "Epoch 3/50 2020-04-04 22:24:30.859511\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aa80748f7036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiGPU\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/00.topse/pytorch/lib/utils.py\u001b[0m in \u001b[0;36mevaluation_start\u001b[0;34m(class_size, batch_size, train_path, val_path, test_path, random_seed_list, net, transform_list, multiGPU, epoch_count)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m### 学習開始\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiGPU\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiGPU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m### テスト\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/00.topse/pytorch/lib/architecture.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, criterion, optimizer, epoch_count, is_inception, multiGPU, cuda, visdom_port)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiGPU\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiGPU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_inception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisdom_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisdom_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# 評価\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/00.topse/pytorch/lib/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data_loader, criterion, optimizer, epoch_count, device, multiGPU, visdom_port, is_inception)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# DataLoaderで取得したデータ分繰り返し学習する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### 学習開始\n",
    "utils.evaluation_start(\n",
    "    class_size=class_size,\n",
    "    batch_size=batch_size,\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    save_root=save_root,\n",
    "    random_seed_list=random_seed_list,\n",
    "    net=None,\n",
    "    transform_list=transform_list,\n",
    "    multiGPU=False,\n",
    "    epoch_count=epoch_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
