{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"31036_Noguchi_SoftDevPrcExc_20191203_v2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"M5-RwpkFQw0y","colab_type":"text"},"source":["参考：\n","\n","[1] Kaggle Kernel: Introduction to CNN Keras - 0.997 (top 6%)\n","\n","(<https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top->)"]},{"cell_type":"markdown","metadata":{"id":"kQqw5L1-4IEC","colab_type":"text"},"source":["# 1.0 Introduction"]},{"cell_type":"markdown","metadata":{"id":"pCp-wNs74Y0m","colab_type":"text"},"source":["以下を記載する。\n","\n","① データセットとして何を選んだか：MNIST(参考Kaggle Kernelと同じ)\n","\n","② 実装面で注意が必要だった点を該当箇所の近辺に\n","\n","③ 日々の作業の進捗を、末尾に、変更履歴のような形で(他のメンバが参照する際に、前回参照時からの差分をすぐに理解できるように)：\n","\n","20191119: 初版\n","\n","20191203: [v2]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LU27nz5QOPnG","colab_type":"text"},"source":["## 1.1 ライブラリをインポート"]},{"cell_type":"markdown","metadata":{"id":"pMdH5j0iL5l5","colab_type":"text"},"source":["インポート時に以下のエラーが発生。\n","\n","---\n","\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.\n","We recommend you upgrade now or ensure your notebook will continue to use TensorFlow 1.x via the %tensorflow_version 1.x magic: more info.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"2F2ABVThLgi3","colab_type":"text"},"source":["TensorFlow version2を指定すると3.1でエラー発生。\n","\n","---\n","It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend\n","\n","---\n"]},{"cell_type":"code","metadata":{"id":"lgvtL6CzYHxc","colab_type":"code","colab":{}},"source":["#%tensorflow_version 2.x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"43SkWtjPQVYU","colab_type":"text"},"source":["最終的にTensorFlowはversion1を指定。"]},{"cell_type":"code","metadata":{"id":"kea2wSrelITE","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvV4Y8DDOQsT","colab_type":"code","colab":{}},"source":["# 各種ライブラリをインポートする。\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","#%matplotlib inline\n","\n","np.random.seed(2)\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from keras.optimizers import RMSprop\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.datasets import mnist\n","\n","sns.set(style='white', context='notebook', palette='deep')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HqZCIOKPgR7S","colab_type":"text"},"source":["# 2.0 Data preparation\n","\n"]},{"cell_type":"markdown","metadata":{"id":"awIM4so0SEeI","colab_type":"text"},"source":["## 2.1 Load data"]},{"cell_type":"code","metadata":{"id":"YAXdQFIjYOCo","colab_type":"code","colab":{}},"source":["# Google Driveをmountする。\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RVoeV79VaFyE","colab_type":"code","colab":{}},"source":["# データセットを読み込む。\n","# データセットはとりあえず参考Kaggle Kernelのものと同じ。\n","# [v2]フォルダ名変更\n","# Load the data\n","train = pd.read_csv(\"/content/drive/My Drive/TopSE/ソフトウェア開発実践演習/Kaggle_Kernel_Input/train.csv\")\n","test = pd.read_csv(\"/content/drive/My Drive/TopSE/ソフトウェア開発実践演習/Kaggle_Kernel_Input/test.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCVe5UTjHmUO","colab_type":"code","cellView":"code","colab":{}},"source":["# トレーニングデータは、labelおよび784次元の画像データであることを確認。\n","train.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtEqbF-n-vwc","colab_type":"code","colab":{}},"source":["# テストデータは、784次元の画像データのみ。\n","test.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRcTehhmbC8i","colab_type":"code","colab":{}},"source":["# trainを、正解ラベルと画像データに分割。\n","# 正解ラベル部分をY_trainに格納。\n","Y_train = train[\"label\"]\n","\n","# 画像データ部分をX_trainに格納。\n","# Drop 'label' column\n","X_train = train.drop(labels = [\"label\"], axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"te_z3zB0G3hG","colab_type":"code","colab":{}},"source":["# Y_trainを確認。\n","Y_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lw6l7xCXG-t5","colab_type":"code","colab":{}},"source":["# X_trainを確認。\n","X_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZN2KE57XGr1u","colab_type":"code","colab":{}},"source":["# 各正解ラベルの出現頻度を確認し、偏りが無いことを確認する。\n","Y_train.value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gX0kLzQdK6Sj","colab_type":"code","colab":{}},"source":["# 上記のラベルごとの出現頻度を可視化。\n","g = sns.countplot(Y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E41an-lruXh2","colab_type":"text"},"source":["##2.2 Check for null and missing values"]},{"cell_type":"code","metadata":{"id":"bvlOrCACucPr","colab_type":"code","colab":{}},"source":["# 欠損値がないことを確認。\n","# Check the data\n","X_train.isnull().any().describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9p3SWcruiaH","colab_type":"code","colab":{}},"source":["test.isnull().any().describe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjfxOQtpe25u","colab_type":"text"},"source":["## 2.3 Normalization"]},{"cell_type":"code","metadata":{"id":"MjnEPTimfnyk","colab_type":"code","colab":{}},"source":["# 0~255の画像データを0~1に正規化する。\n","# 一般的に0~1または-1~1の値域に正規化する。\n","# Normalize the data\n","X_train = X_train / 255.0\n","test = test / 255.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RX7FcKPPfohB","colab_type":"text"},"source":["## 2.4 Reshape"]},{"cell_type":"code","metadata":{"id":"cekXPl8zfvOi","colab_type":"code","colab":{}},"source":["# reshape(-1,28,28,1)の-1は、サイズ不変を意味するとのこと。\n","# Reshape image in 3 dimensions (height = 28px, width = 28px, cannel = 1)\n","X_train = X_train.values.reshape(-1,28,28,1)\n","test = test.values.reshape(-1,28,28,1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ulz_sakgjQk2","colab_type":"text"},"source":["## 2.5 Label encoding"]},{"cell_type":"code","metadata":{"id":"qMZw68EyjTAD","colab_type":"code","colab":{}},"source":["# 0~9のラベルをone hot vectorsに変換。\n","# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n","Y_train = to_categorical(Y_train, num_classes = 10)\n","print(\"Y_train: \", Y_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkPefDVSjV9e","colab_type":"text"},"source":["## 2.6 Split training and valdiation set"]},{"cell_type":"code","metadata":{"id":"pTOziQTTjaJO","colab_type":"code","colab":{}},"source":["# 学習用とテスト用のデータを分割。\n","# テスト用のデータの割合を10%に指定。\n","\n","# Set the random seed\n","random_seed = 2\n","# Split the train and the validation set for the fitting\n","X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zjlRxiP0WnY","colab_type":"code","colab":{}},"source":["print(\"X_train:\", X_train.shape)\n","print(\"X_val:\", X_val.shape)\n","print(\"Y_train:\", Y_train.shape)\n","print(\"Y_val:\", Y_val.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZnrOXfMjfXK","colab_type":"code","colab":{}},"source":["# Some examples\n","g = plt.imshow(X_train[0][:,:,0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D5HAx3prmTwj","colab_type":"text"},"source":["# 3.0 CNN"]},{"cell_type":"markdown","metadata":{"id":"JQgvBBh9mf32","colab_type":"text"},"source":["## 3.1 Define the model"]},{"cell_type":"code","metadata":{"id":"RIADfXv7mWUN","colab_type":"code","colab":{}},"source":["# Set the CNN model \n","# my CNN architechture is \n","# In ->\n","# [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> \n","# Flatten -> \n","# Dense -> \n","# Dropout \n","# -> Out\n","\n","model = Sequential()\n","\n","model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', \n","                 activation ='relu', input_shape = (28,28,1)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', \n","                 activation ='relu'))\n","model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation = \"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation = \"softmax\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JULDhOEwqqMO","colab_type":"code","colab":{}},"source":["# [v2]CNNモデルの全体像を確認。\n","# Paramの数値はどのように算出できる？\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQ_vLnAinasj","colab_type":"text"},"source":["## 3.2 Set the optimizer and annealer"]},{"cell_type":"code","metadata":{"id":"LS-gd9MPIHPm","colab_type":"code","colab":{}},"source":["# [v2] RMSPropの引数はデフォルトでの使用を推奨されているが、epsilonがデフォルトではない模様。(デフォルト=None)\n","# Define the optimizer\n","optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CReh7xOBIJT3","colab_type":"code","colab":{}},"source":["# [v2] 誤差関数はクロスエントロピー。評価関数は学習時には無関係。\n","# Compile the model\n","model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bG8ROw6aPTJ5","colab_type":"code","colab":{}},"source":["# [v2] 3エポックの間、誤差関数が小さくならなくなったら、学習率を半分に下げる。\n","# Set a learning rate annealer\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.00001)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrjXkxPxPUle","colab_type":"code","colab":{}},"source":["epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\n","batch_size = 86"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQd9EsAtRCsO","colab_type":"text"},"source":["## 3.3 Data augmentation"]},{"cell_type":"code","metadata":{"id":"AAsN3DLNSzH9","colab_type":"code","colab":{}},"source":["# Without data augmentation i obtained an accuracy of 0.98114\n","#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n","#          validation_data = (X_val, Y_val), verbose = 2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdxAoJZLS0tJ","colab_type":"code","colab":{}},"source":["# [v2] 回転および平行移動でaugumentationを実施。\n","# [v2] degrees, 0 to 180 -> -10 to 10 では？\n","# With data augmentation to prevent overfitting (accuracy 0.99286)\n","\n","datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.1, # Randomly zoom image \n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=False,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","\n","datagen.fit(X_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pSSqeF0TI6D","colab_type":"code","colab":{}},"source":["# [v2] ミニバッチごとに前処理を行う場合はfitの代わりにfit.generatorを使用する。\n","# Fit the model\n","history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n","                              epochs = epochs, validation_data = (X_val,Y_val),\n","                              verbose = 2, steps_per_epoch = X_train.shape[0] // batch_size,\n","                              callbacks = [learning_rate_reduction])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uxd1WiQQTcCp","colab_type":"text"},"source":["## [Additional] 3.4 Export Trained Model"]},{"cell_type":"code","metadata":{"id":"J3QlildTTazg","colab_type":"code","colab":{}},"source":["# [v2] 学習済みのモデルをGoogle Driveにエクスポートしておく。\n","model.save('/content/drive/My Drive/TopSE/ソフトウェア開発実践演習/Kaggle_Kernel_Input/TrainedModel.hd5')\n","!ls -lh '/content/drive/My Drive/TopSE/ソフトウェア開発実践演習/Kaggle_Kernel_Input/TrainedModel.hd5'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PF9f4sfiTQCy","colab_type":"text"},"source":["# 4. Evaluate the model"]},{"cell_type":"markdown","metadata":{"id":"xeoQpIUFTSk_","colab_type":"text"},"source":["## 4.1 Training and validation curves"]},{"cell_type":"code","metadata":{"id":"hJPnAnKTTVvm","colab_type":"code","colab":{}},"source":["# [v2] epoch=2以上にしないとグラフは表示されない。\n","# Plot the loss and accuracy curves for training and validation \n","fig, ax = plt.subplots(2,1)\n","ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n","ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n","legend = ax[0].legend(loc='best', shadow=True)\n","\n","ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n","ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n","legend = ax[1].legend(loc='best', shadow=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-cvguf9jThIY","colab_type":"text"},"source":["## 4.2 Confusion matrix"]},{"cell_type":"code","metadata":{"id":"u9GHDX0nTjnh","colab_type":"code","colab":{}},"source":["# Look at confusion matrix \n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","# Predict the values from the validation dataset\n","Y_pred = model.predict(X_val)\n","# Convert predictions classes to one hot vectors \n","Y_pred_classes = np.argmax(Y_pred,axis = 1) \n","# Convert validation observations to one hot vectors\n","Y_true = np.argmax(Y_val,axis = 1) \n","# compute the confusion matrix\n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","# plot the confusion matrix\n","plot_confusion_matrix(confusion_mtx, classes = range(10)) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZdUL_pzTmNv","colab_type":"code","colab":{}},"source":["# Display some error results \n","\n","# Errors are difference between predicted labels and true labels\n","errors = (Y_pred_classes - Y_true != 0)\n","\n","Y_pred_classes_errors = Y_pred_classes[errors]\n","Y_pred_errors = Y_pred[errors]\n","Y_true_errors = Y_true[errors]\n","X_val_errors = X_val[errors]\n","\n","def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n","    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n","    n = 0\n","    nrows = 2\n","    ncols = 3\n","    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n","    for row in range(nrows):\n","        for col in range(ncols):\n","            error = errors_index[n]\n","            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n","            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n","            n += 1\n","\n","# Probabilities of the wrong predicted numbers\n","Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n","\n","# Predicted probabilities of the true values in the error set\n","true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n","\n","# Difference between the probability of the predicted label and the true label\n","delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n","\n","# Sorted list of the delta prob errors\n","sorted_dela_errors = np.argsort(delta_pred_true_errors)\n","\n","# Top 6 errors \n","most_important_errors = sorted_dela_errors[-6:]\n","\n","# Show the top 6 errors\n","display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q-Q0WHxfTufm","colab_type":"code","colab":{}},"source":["# predict results\n","results = model.predict(test)\n","\n","# select the indix with the maximum probability\n","results = np.argmax(results,axis = 1)\n","\n","results = pd.Series(results,name=\"Label\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbUTkwBNTvl-","colab_type":"code","colab":{}},"source":["submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n","\n","submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"],"execution_count":0,"outputs":[]}]}