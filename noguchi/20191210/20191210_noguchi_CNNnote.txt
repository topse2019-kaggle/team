・環境が違うと挙動が変わるなどの場合、TensorFlowやKerasのバージョンを確認する。
　→バージョンによって挙動が異なる場合がある。
・pytorchでGPUを使うときは、GPUにモデルを置かないと使われない。
　→.cudaメソッドを使う。
・kerasは自動的にGPUを使うようになっている模様。
　→Cloud上で運用する場合などには課金条件に注意。
・畳み込みフィルタのfilterは別々のフィルタ32枚ではない。
　→32レイヤを持った1枚のフィルタだと考える。
・32レイヤだとすると、1回目のフィルタ当てた結果に対して2枚目のフィルタを当てる...ではなく、同時に32個の何らかの特徴を抽出しようとしている。
・畳み込みフィルタのkernelは、最初はランダムやゼロ。
　どのような特徴を抽出するか、も含めて学習していく。
・フィルタ(kernel)の中身の初期値はどうなっているか。
　→なんでもいい。乱数など。
　→フィルタの中身そのものも機械学習で学習していく。（勾配降下法による最適化の対象）
　→誤差関数が最小になるような適切なフィルタが自動的に得られる。
・フィルタの数を増やすとき、慣例的にフィルタのサイズを小さくする
　→より細かい部分の特徴を抽出しようとしている。
・MNISTのようにデータセットが基本的で簡単な場合、複雑なネットワークを適用してしまうと、学習する力が強すぎて過学習を起こし画像を記憶してしまう。





