{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04_Introduction to U-net with simple Resnet Blocks.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"50f0614803c042c4a2036d3bc05cee26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_15cd627bf8ec4b7785daeb782a69d836","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b45ea49b49194cd1abbd1c269a3799fc","IPY_MODEL_eace505bcc2a4d97b49c6c4d87a26964"]}},"15cd627bf8ec4b7785daeb782a69d836":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b45ea49b49194cd1abbd1c269a3799fc":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a0810bc8d7784d5ebc2c10a38b6bf9cf","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"","max":4000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97a566cf33bf4d569cf5d65b31d88dde"}},"eace505bcc2a4d97b49c6c4d87a26964":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b9bbdde3e10247ba8399ab0605674e32","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  0% 0/4000 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_18d96490f91941fd9f3336e96552a0a5"}},"a0810bc8d7784d5ebc2c10a38b6bf9cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"97a566cf33bf4d569cf5d65b31d88dde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9bbdde3e10247ba8399ab0605674e32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"18d96490f91941fd9f3336e96552a0a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"YIcPTP1vP01a","colab_type":"text"},"source":["# Residual Network\n","\n","以下を再現\n","\n","Introduction to U-net with simple Resnet Blocks\n","\n","https://www.kaggle.com/deepaksinghrawat/introduction-to-u-net-with-simple-resnet-blocks"]},{"cell_type":"code","metadata":{"id":"AQvY2ucUyAfQ","colab_type":"code","outputId":"7241c6ea-3adc-4b4e-b4d7-3cd1d52124b3","executionInfo":{"status":"ok","timestamp":1577036426242,"user_tz":-540,"elapsed":4070,"user":{"displayName":"平河正博","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAdlZL720isHfYPaHssMdeXrZaOzTv1hHlF4PPNpQ=s64","userId":"18297374935424919168"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["import os\n","import sys\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","plt.style.use('seaborn-white')\n","import seaborn as sns\n","sns.set_style(\"white\")\n","\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm import tqdm_notebook #, tnrange\n","#from itertools import chain\n","from skimage.io import imread, imshow #, concatenate_images\n","from skimage.transform import resize\n","from skimage.morphology import label\n","\n","from keras.models import Model, load_model, save_model\n","from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n","from keras.layers.core import Lambda\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.merge import concatenate\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras import backend as K\n","from keras import optimizers\n","\n","import tensorflow as tf\n","\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n","import imgaug\n","imgaug.seed(1)\n","import time\n","t_start = time.time()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"6z0II6Lyslrt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"905d5c97-8736-4afa-b08d-c54e499ce86f","executionInfo":{"status":"ok","timestamp":1577036447007,"user_tz":-540,"elapsed":936,"user":{"displayName":"平河正博","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAdlZL720isHfYPaHssMdeXrZaOzTv1hHlF4PPNpQ=s64","userId":"18297374935424919168"}}},"source":["version = 5\n","basic_name = f'Unet_resnet_v{version}'\n","save_model_name = basic_name + '.model'\n","submission_file = basic_name + '.csv'\n","\n","print(save_model_name)\n","print(submission_file)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Unet_resnet_v5.model\n","Unet_resnet_v5.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hbUQwkM-sled","colab_type":"code","colab":{}},"source":["img_size_ori = 101\n","img_size_target = 101\n","\n","def upsample(img):\n","    if img_size_ori == img_size_target:\n","        return img\n","    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n","    \n","def downsample(img):\n","    if img_size_ori == img_size_target:\n","        return img\n","    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uB98uRpKsufC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"324c4fef-1b58-4c34-fee6-e78badd95fc1","executionInfo":{"status":"ok","timestamp":1577037329074,"user_tz":-540,"elapsed":834,"user":{"displayName":"平河正博","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAdlZL720isHfYPaHssMdeXrZaOzTv1hHlF4PPNpQ=s64","userId":"18297374935424919168"}}},"source":["# Loading of training/testing ids and depths\n","train_df = pd.read_csv(\"./input/train.csv\", index_col=\"id\", usecols=[0])\n","depths_df = pd.read_csv(\"./input/depths.csv\", index_col=\"id\")\n","train_df = train_df.join(depths_df)\n","test_df = depths_df[~depths_df.index.isin(train_df.index)]\n","\n","len(train_df)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4000"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"2Y2ZbTVlszfG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":397,"referenced_widgets":["50f0614803c042c4a2036d3bc05cee26","15cd627bf8ec4b7785daeb782a69d836","b45ea49b49194cd1abbd1c269a3799fc","eace505bcc2a4d97b49c6c4d87a26964","a0810bc8d7784d5ebc2c10a38b6bf9cf","97a566cf33bf4d569cf5d65b31d88dde","b9bbdde3e10247ba8399ab0605674e32","18d96490f91941fd9f3336e96552a0a5"]},"outputId":"72b60866-c0fc-4165-9d43-cf9585de1412","executionInfo":{"status":"error","timestamp":1577040506572,"user_tz":-540,"elapsed":4162,"user":{"displayName":"平河正博","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAdlZL720isHfYPaHssMdeXrZaOzTv1hHlF4PPNpQ=s64","userId":"18297374935424919168"}}},"source":["train_df[\"images\"] = [np.array(load_img(\"./input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50f0614803c042c4a2036d3bc05cee26","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n","  warnings.warn('grayscale is deprecated. Please use '\n"],"name":"stderr"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f981a45bb571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./input/train/images/{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-f981a45bb571>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./input/train/images/{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/train/images/ef51bbcde7.png'"]}]},{"cell_type":"code","metadata":{"id":"53L382ZGwzGu","colab_type":"code","colab":{}},"source":["train_df[\"masks\"] = [np.array(load_img(\"./input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cvupvAOswJ9h","colab_type":"code","colab":{}},"source":["train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n","\n","def cov_to_class(val):    \n","    for i in range(0, 11):\n","        if val * 10 <= i :\n","            return i\n","        \n","train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpOaQckDw4qV","colab_type":"code","colab":{}},"source":["SUBSET = len(train_df)\n","train_df = train_df.head(SUBSET)\n","len(train_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDAvQ48yw7R8","colab_type":"code","colab":{}},"source":["fig, axs = plt.subplots(1, 2, figsize=(15,5))\n","sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n","sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n","plt.suptitle(\"Salt coverage\")\n","axs[0].set_xlabel(\"Coverage\")\n","axs[1].set_xlabel(\"Coverage class\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YH7NfmqGw4bx","colab_type":"code","colab":{}},"source":["#Plotting the depth distributions\n","\n","sns.distplot(train_df.z, label=\"Train\")\n","sns.distplot(test_df.z, label=\"Test\")\n","plt.legend()\n","plt.title(\"Depth distribution\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6LKMRiRYxCfj","colab_type":"code","colab":{}},"source":["def plot2x2Array(image, mask):\n","    f, axarr = plt.subplots(1,2)\n","    axarr[0].imshow(image, cmap=\"gray\")\n","    axarr[1].imshow(mask, cmap=\"gray\")\n","    axarr[0].grid(False)\n","    axarr[1].grid(False)\n","    axarr[0].set_title('Image')\n","    axarr[1].set_title('Mask')\n","    \n","for i, idx in enumerate(train_df.index[:10]):\n","    img = train_df.loc[idx].images\n","    mask = train_df.loc[idx].masks\n","    plot2x2Array(img, mask)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsiijhQOxCOd","colab_type":"code","colab":{}},"source":["max_images = 60\n","grid_width = 15\n","grid_height = int(max_images / grid_width)\n","fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\n","for i, idx in enumerate(train_df.index[:max_images]):\n","    img = train_df.loc[idx].images\n","    mask = train_df.loc[idx].masks\n","    ax = axs[int(i / grid_width), i % grid_width]\n","    ax.imshow(img, cmap=\"Greys\")\n","    ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n","    ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n","    ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n","    ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n","    ax.set_yticklabels([])\n","    ax.set_xticklabels([])\n","plt.suptitle(\"Green: salt. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIol1bJwxKqK","colab_type":"code","colab":{}},"source":["# Create train/validation split stratified by salt coverage\n","\n","ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n","    train_df.index.values,\n","    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n","    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n","    train_df.coverage.values,\n","    train_df.z.values,\n","    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUAcBuvLxOPA","colab_type":"code","colab":{}},"source":["def BatchActivate(x):\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    return x\n","\n","def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n","    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n","    if activation == True:\n","        x = BatchActivate(x)\n","    return x\n","\n","def residual_block(blockInput, num_filters=16, batch_activate = False):\n","    x = BatchActivate(blockInput)\n","    x = convolution_block(x, num_filters, (3,3) )\n","    x = convolution_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, blockInput])\n","    if batch_activate:\n","        x = BatchActivate(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MiAAshDrxRow","colab_type":"code","colab":{}},"source":["# Build model\n","def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n","    # 101 -> 50\n","    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n","    conv1 = residual_block(conv1,start_neurons * 1)\n","    conv1 = residual_block(conv1,start_neurons * 1, True)\n","    pool1 = MaxPooling2D((2, 2))(conv1)\n","    pool1 = Dropout(DropoutRatio/2)(pool1)\n","\n","    # 50 -> 25\n","    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n","    conv2 = residual_block(conv2,start_neurons * 2)\n","    conv2 = residual_block(conv2,start_neurons * 2, True)\n","    pool2 = MaxPooling2D((2, 2))(conv2)\n","    pool2 = Dropout(DropoutRatio)(pool2)\n","\n","    # 25 -> 12\n","    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n","    conv3 = residual_block(conv3,start_neurons * 4)\n","    conv3 = residual_block(conv3,start_neurons * 4, True)\n","    pool3 = MaxPooling2D((2, 2))(conv3)\n","    pool3 = Dropout(DropoutRatio)(pool3)\n","\n","    # 12 -> 6\n","    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n","    conv4 = residual_block(conv4,start_neurons * 8)\n","    conv4 = residual_block(conv4,start_neurons * 8, True)\n","    pool4 = MaxPooling2D((2, 2))(conv4)\n","    pool4 = Dropout(DropoutRatio)(pool4)\n","\n","    # Middle\n","    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n","    convm = residual_block(convm,start_neurons * 16)\n","    convm = residual_block(convm,start_neurons * 16, True)\n","    \n","    # 6 -> 12\n","    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","    uconv4 = concatenate([deconv4, conv4])\n","    uconv4 = Dropout(DropoutRatio)(uconv4)\n","    \n","    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n","    uconv4 = residual_block(uconv4,start_neurons * 8)\n","    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n","    \n","    # 12 -> 25\n","    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n","    uconv3 = concatenate([deconv3, conv3])    \n","    uconv3 = Dropout(DropoutRatio)(uconv3)\n","    \n","    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n","    uconv3 = residual_block(uconv3,start_neurons * 4)\n","    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n","\n","    # 25 -> 50\n","    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","    uconv2 = concatenate([deconv2, conv2])\n","        \n","    uconv2 = Dropout(DropoutRatio)(uconv2)\n","    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n","    uconv2 = residual_block(uconv2,start_neurons * 2)\n","    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n","    \n","    # 50 -> 101\n","    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n","    uconv1 = concatenate([deconv1, conv1])\n","    \n","    uconv1 = Dropout(DropoutRatio)(uconv1)\n","    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n","    uconv1 = residual_block(uconv1,start_neurons * 1)\n","    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n","    \n","    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n","    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n","    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n","    output_layer =  Activation('sigmoid')(output_layer_noActi)\n","    \n","    return output_layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o1Issw8exaoj","colab_type":"code","colab":{}},"source":["def get_iou_vector(A, B):\n","    batch_size = A.shape[0]\n","    metric = []\n","    for batch in range(batch_size):\n","        t, p = A[batch]>0, B[batch]>0\n","        intersection = np.logical_and(t, p)\n","        union = np.logical_or(t, p)\n","        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n","        thresholds = np.arange(0.5, 1, 0.05)\n","        s = []\n","        for thresh in thresholds:\n","            s.append(iou > thresh)\n","        metric.append(np.mean(s))\n","\n","    return np.mean(metric)\n","\n","def my_iou_metric(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n","\n","def my_iou_metric_2(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbHzhTz9xd-t","colab_type":"code","colab":{}},"source":["# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    gts = tf.reduce_sum(gt_sorted)\n","    intersection = gts - tf.cumsum(gt_sorted)\n","    union = gts + tf.cumsum(1. - gt_sorted)\n","    jaccard = 1. - intersection / union\n","    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n","    return jaccard\n","\n","\n","# --------------------------- BINARY LOSSES ---------------------------\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        def treat_image(log_lab):\n","            log, lab = log_lab\n","            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n","            log, lab = flatten_binary_scores(log, lab, ignore)\n","            return lovasz_hinge_flat(log, lab)\n","        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n","        loss = tf.reduce_mean(losses)\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","\n","    def compute_loss():\n","        labelsf = tf.cast(labels, logits.dtype)\n","        signs = 2. * labelsf - 1.\n","        errors = 1. - logits * tf.stop_gradient(signs)\n","        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n","        gt_sorted = tf.gather(labelsf, perm)\n","        grad = lovasz_grad(gt_sorted)\n","        #loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n","        loss = tf.tensordot(tf.nn.elu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n","        return loss\n","\n","    # deal with the void prediction case (only void pixels)\n","    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n","                   lambda: tf.reduce_sum(logits) * 0.,\n","                   compute_loss,\n","                   strict=True,\n","                   name=\"loss\"\n","                   )\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = tf.reshape(scores, (-1,))\n","    labels = tf.reshape(labels, (-1,))\n","    if ignore is None:\n","        return scores, labels\n","    valid = tf.not_equal(labels, ignore)\n","    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n","    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n","    return vscores, vlabels\n","\n","def lovasz_loss(y_true, y_pred):\n","    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n","    #logits = K.log(y_pred / (1. - y_pred))\n","    logits = y_pred #Jiaxin\n","    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bny--rApxipM","colab_type":"code","colab":{}},"source":["#Data augmentation\n","x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n","y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n","print(x_train.shape)\n","print(y_valid.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLxXQof-xaQY","colab_type":"code","colab":{}},"source":["# model\n","\n","learning_rate = 0.01\n","input_layer = Input((img_size_target, img_size_target, 1))\n","output_layer = build_model(input_layer, 16,0.5)\n","\n","model1 = Model(input_layer, output_layer)\n","\n","c = optimizers.adam(lr = learning_rate)\n","model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n","\n","#model1.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRqYcjilxtts","colab_type":"code","colab":{}},"source":["early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=10, verbose=1)\n","model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n","                                   mode = 'max', save_best_only=True, verbose=1)\n","reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n","\n","epochs = 100\n","batch_size = 32\n","history = model1.fit(x_train, y_train,\n","                    validation_data=[x_valid, y_valid], \n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    callbacks=[early_stopping, model_checkpoint,reduce_lr], \n","                    verbose=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1Sa0CNbxsOV","colab_type":"code","colab":{}},"source":["model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n","# remove later activation layer and use losvasz loss\n","input_x = model1.layers[0].input\n","\n","output_layer = model1.layers[-1].input\n","model = Model(input_x, output_layer)\n","c = optimizers.adam(lr = learning_rate)\n","\n","# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n","# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n","model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n","\n","#model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQY1fWUFxKNu","colab_type":"code","colab":{}},"source":["early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n","model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n","                                   mode = 'max', save_best_only=True, verbose=1)\n","reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n","epochs = 200\n","batch_size = 32\n","\n","history = model.fit(x_train, y_train,\n","                    validation_data=[x_valid, y_valid], \n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    callbacks=[ model_checkpoint,reduce_lr,early_stopping], \n","                    verbose=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZNa99iLwJwc","colab_type":"code","colab":{}},"source":["fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n","ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n","ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n","ax_loss.legend()\n","ax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\n","ax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\n","ax_score.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"em-XE1H5x9Wu","colab_type":"code","colab":{}},"source":["model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n","                                                   'lovasz_loss': lovasz_loss})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y0uR_bXgyAFv","colab_type":"code","colab":{}},"source":["def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n","    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n","    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n","    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n","    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n","    return preds_test/2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7QDB6wxUyC2u","colab_type":"code","colab":{}},"source":["preds_valid = predict_result(model,x_valid,img_size_target)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j8wL4fG3yCrr","colab_type":"code","colab":{}},"source":["#Score the model and do a threshold optimization by the best IoU.\n","\n","# src: https://www.kaggle.com/aglotero/another-iou-metric\n","def iou_metric(y_true_in, y_pred_in, print_table=False):\n","    labels = y_true_in\n","    y_pred = y_pred_in\n","\n","\n","    true_objects = 2\n","    pred_objects = 2\n","\n","    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n","    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n","\n","    intersection = temp1[0]\n","\n","    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n","    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n","    area_true = np.expand_dims(area_true, -1)\n","    area_pred = np.expand_dims(area_pred, 0)\n","\n","    # Compute union\n","    union = area_true + area_pred - intersection\n","      \n","    # Exclude background from the analysis\n","    intersection = intersection[1:,1:]\n","    intersection[intersection == 0] = 1e-9\n","    \n","    union = union[1:,1:]\n","    union[union == 0] = 1e-9\n","\n","    # Compute the intersection over union\n","    iou = intersection / union\n","\n","    # Precision helper function\n","    def precision_at(threshold, iou):\n","        matches = iou > threshold\n","        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n","        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n","        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n","        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n","        return tp, fp, fn\n","\n","    # Loop over IoU thresholds\n","    prec = []\n","    if print_table:\n","        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        tp, fp, fn = precision_at(t, iou)\n","        if (tp + fp + fn) > 0:\n","            p = tp / (tp + fp + fn)\n","        else:\n","            p = 0\n","        if print_table:\n","            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n","        prec.append(p)\n","    \n","    if print_table:\n","        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n","    return np.mean(prec)\n","\n","def iou_metric_batch(y_true_in, y_pred_in):\n","    batch_size = y_true_in.shape[0]\n","    metric = []\n","    for batch in range(batch_size):\n","        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n","        metric.append(value)\n","    return np.mean(metric)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKYJ64_JyIjo","colab_type":"code","colab":{}},"source":["## Scoring for last model, choose threshold by validation data \n","thresholds_ori = np.linspace(0.3, 0.7, 31)\n","# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n","thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n","\n","# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n","# print(ious)\n","ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n","print(ious)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpknyUPHyMA7","colab_type":"code","colab":{}},"source":["# instead of using default 0 as threshold, use validation data to find the best threshold.\n","threshold_best_index = np.argmax(ious) \n","iou_best = ious[threshold_best_index]\n","threshold_best = thresholds[threshold_best_index]\n","\n","plt.plot(thresholds, ious)\n","plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n","plt.xlabel(\"Threshold\")\n","plt.ylabel(\"IoU\")\n","plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rG-3vsKryOfo","colab_type":"code","colab":{}},"source":["\"\"\"\n","used for converting the decoded image to rle mask\n","Fast compared to previous one\n","\"\"\"\n","def rle_encode(im):\n","    '''\n","    im: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    pixels = im.flatten(order = 'F')\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPExIf-SyRGG","colab_type":"code","colab":{}},"source":["x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oniz-mjFyIUz","colab_type":"code","colab":{}},"source":["preds_test = predict_result(model,x_test,img_size_target)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8AToNQayTnv","colab_type":"code","colab":{}},"source":["t1 = time.time()\n","pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n","t2 = time.time()\n","\n","print(f\"Usedtime = {t2-t1} s\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dVTJad-yZSD","colab_type":"code","colab":{}},"source":["sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n","sub.index.names = ['id']\n","sub.columns = ['rle_mask']\n","sub.to_csv(submission_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aAwbulquyZD0","colab_type":"code","colab":{}},"source":["t_finish = time.time()\n","print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"],"execution_count":0,"outputs":[]}]}