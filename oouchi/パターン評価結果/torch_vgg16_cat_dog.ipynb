{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62hiZT6s_gsm"
   },
   "source": [
    "# Pytorch VGG16（Cat and Dog）初心者の視点で実装したバージョン\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnVu7DfYAwXE"
   },
   "source": [
    "【お題】\n",
    "- 検証用データセット「Cat and Dog」を用いて画像分類のための機械学習モデルを構築する。\n",
    " - 「Cat and Dog」データセット\n",
    "   - 画像数：16010(学習：12808、検証：3202）\n",
    "   - 画像サイズ：64×64\n",
    "   - クラス数：2（cats、dogs）\n",
    "  - データセットの入手先：\n",
    "   - https://www.kaggle.com/tongpython/cat-and-dog\n",
    "    - cat-and-dog.zip\n",
    "\n",
    "【提出物】\n",
    "- モデル学習時のepochごとのAccurncy、loss値の推移が分かるもの。\n",
    "- モデル構築後、検証用画像に対してモデルを適用した際の、Accurncyが分かるもの。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJW657mwg44O"
   },
   "source": [
    "## ■目次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48ZMNIB_ZUGT"
   },
   "source": [
    "- モジュールの読み込み等\n",
    "- Google Colaboratory を使うための準備\n",
    "- 入力データ(学習、評価) 整備\n",
    "- モデル定義\n",
    "- 学習\n",
    "- 評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OxbecpASr4Rs"
   },
   "source": [
    "## ■モジュールの読み込み等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4acTFuRov3Eo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary # summary(your_model, input_size=(channels, H, W))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import requests # URLリクエストを簡単に行う。pip install requests が必要\n",
    "from urllib import request # 指定URLのファイルを保存する\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDFnJKMhAEG7"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PlOWBqNAKh0"
   },
   "outputs": [],
   "source": [
    "# 割当てられたGPUの確認\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDHaUnd0HeTl"
   },
   "source": [
    "## ■Google Colaboratory を使うための準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_5PCQTnZnd3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "%cd '/content/drive/My Drive/'\n",
    "\n",
    "if not os.path.exists('tmp'): # 12時間ルール対策用フォルダ\n",
    "    os.makedirs('tmp')\n",
    "\n",
    "# 【使用例】\n",
    "#sys.stdout = open('/content/drive/My Drive/tmp/result.txt', 'a')\n",
    "# …とても時間のかかる処理（学習処理など）…\n",
    "#sys.stdout.close()\n",
    "#sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bK3qCoKazI19"
   },
   "source": [
    "## ■入力データ(学習、評価) 整備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WO-9GLXeC9oS"
   },
   "source": [
    "1. torchvision.datasetsで入手できるもの（MNIST, CIFAR10など）はこちらを使う。\n",
    "2. torchvision.datasetsで入手できないものは、Kaggle等から入手したデータセット（ZIP）をGoogle Driveに予めアップロードしておく。\n",
    " - データセット仕様（フォルダ構成など）は、学習(train)と評価(val)データの振り分け処理のために、事前に把握しておくこと。\n",
    " - Sign Language MNISTなど、画像ファイルでなくCSVで提供されるデータセットは自分で画像ファイルに変換しZIP化したものをアップロードする。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MG10y23HO1Gj"
   },
   "source": [
    "### データセットをColabo VMに展開"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5T_Gag-DxgO"
   },
   "outputs": [],
   "source": [
    "gdrive_dir = \"/content/drive/My Drive/Colab Notebooks/dataset/\"\n",
    "download_dir = \"/root/download/\"\n",
    "data_dir = \"/root/data/\"\n",
    "zip_file_name = \"cat-and-dog.zip\"\n",
    "\n",
    "!rm -rf $data_dir\n",
    "\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVfewmiZmcxB"
   },
   "outputs": [],
   "source": [
    "# Colab VMのストレージにDLする\n",
    "%%time\n",
    "s = gdrive_dir + zip_file_name\n",
    "shutil.copy(s, download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VlepMovmKLt"
   },
   "outputs": [],
   "source": [
    "# Colab VMのストレージに解凍する\n",
    "%%time\n",
    "f = os.path.join(download_dir, zip_file_name)\n",
    "with zipfile.ZipFile(f) as zip:\n",
    "  zip.extractall(download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKF8Nff0Dxb3"
   },
   "outputs": [],
   "source": [
    "os.chdir(download_dir)\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHxE747bYog0"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idYBTUclWaS8"
   },
   "source": [
    "### 学習データ(train)と評価データ(validation)の振分け"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQGj63kwPOT3"
   },
   "source": [
    "- 本ファイルが扱うデータセットの学習データと評価データは、解凍直後の段階で既に、におよそ 75％：25％ の割合でフォルダ別に仕切られている。\n",
    "- この割合で学習を評価を行うことにする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1AxrjhzS73S"
   },
   "source": [
    "#### 学習データの振分け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxVUmWe_PlTE"
   },
   "outputs": [],
   "source": [
    "# ラベル名を確認する\n",
    "src_dir = '/root/download/training_set/training_set/'\n",
    "dst_dir = '/root/data/cat_and_dog/train/'\n",
    "\n",
    "!rm -rf $dst_dir\n",
    "os.makedirs(dst_dir)\n",
    "\n",
    "os.chdir(src_dir)\n",
    "label_dirs = os.listdir(path='.')\n",
    "print(label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXKTc_vvQMJ_"
   },
   "outputs": [],
   "source": [
    "# 所定フォルダに振り分ける\n",
    "for dir_name in label_dirs:\n",
    "  numof_data = len( os.listdir(src_dir + dir_name)) # ラベルフォルダ内のファイル数\n",
    "  files = glob.glob(src_dir + dir_name + \"/*.jpg\")  # ラベルフォルダ内のファイルリスト\n",
    "\n",
    "  print(\"Number of data in \" + dir_name + \": \" + str(numof_data))\n",
    "  for file in files:\n",
    "    d = dst_dir + dir_name # 振り分け先フォルダ\n",
    "    if not os.path.exists(d):\n",
    "      os.makedirs(d)\n",
    "    shutil.move(file, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RF1I9bJsS3MB"
   },
   "outputs": [],
   "source": [
    "# 意図通りに振り分けられたか確認する（今回は目視で確認）\n",
    "print(\"Train files in \" + dst_dir)\n",
    "for dir_name in label_dirs:\n",
    "  numof_data = len( os.listdir(dst_dir + dir_name)) # ラベルフォルダ内のファイル数\n",
    "  print(\" \" + dir_name + \": \" + str(numof_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4Qo0iqLUwTu"
   },
   "source": [
    "#### 評価データの振分け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o7w6DBEUS3Wh"
   },
   "outputs": [],
   "source": [
    "# ラベル名を確認する\n",
    "src_dir = '/root/download/test_set/test_set/'\n",
    "dst_dir = '/root/data/cat_and_dog/test/'\n",
    "\n",
    "!rm -rf $dst_dir\n",
    "os.makedirs(dst_dir)\n",
    "\n",
    "os.chdir(src_dir)\n",
    "label_dirs = os.listdir(path='.')\n",
    "print(label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecUp3tH6Uqtk"
   },
   "outputs": [],
   "source": [
    "# 所定フォルダに振り分ける\n",
    "for dir_name in label_dirs:\n",
    "  numof_data = len( os.listdir(src_dir + dir_name)) # ラベルフォルダ内のファイル数\n",
    "  files = glob.glob(src_dir + dir_name + \"/*.jpg\")  # ラベルフォルダ内のファイルリスト\n",
    "\n",
    "  print(\"Number of data in \" + dir_name + \": \" + str(numof_data))\n",
    "  for file in files:\n",
    "    d = dst_dir + dir_name # 振り分け先フォルダ\n",
    "    if not os.path.exists(d):\n",
    "      os.makedirs(d)\n",
    "    shutil.move(file, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6b2EI0HyUq2i"
   },
   "outputs": [],
   "source": [
    "# 意図通りに振り分けられたか確認する（今回は目視で確認）\n",
    "print(\"Validation files in \" + dst_dir)\n",
    "for dir_name in label_dirs:\n",
    "  numof_data = len( os.listdir(dst_dir + dir_name)) # ラベルフォルダ内のファイル数\n",
    "  print(\" \" + dir_name + \": \" + str(numof_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RvbabYWEt0J8"
   },
   "source": [
    "### データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLfQ_QVdYEyr"
   },
   "outputs": [],
   "source": [
    "dst_dir = '/root/data/cat_and_dog/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqiPIB_B24bF"
   },
   "outputs": [],
   "source": [
    "# VGGモデル入力を行うための画像のフォーマット変換\n",
    "my_size = 224\n",
    "my_mean = (0.485, 0.456, 0.406) # ILSVRC2012に基づくデータセットを使う場合の設定値\n",
    "my_std = (0.229, 0.224, 0.225) # ILSVRC2012に基づくデータセットを使う場合の設定値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVOZFY8PrZ-w"
   },
   "outputs": [],
   "source": [
    "tf_train = transforms.Compose([\n",
    "     transforms.Resize((my_size, my_size)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5),\n",
    "     transforms.RandomRotation(90),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(my_mean, my_std)])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root = dst_dir + 'train', transform=tf_train) \n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mY1uG8TurZ8x"
   },
   "outputs": [],
   "source": [
    "tf_val = transforms.Compose([\n",
    "     transforms.Resize((my_size, my_size)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(my_mean, my_std)])\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root = dst_dir + 'test', transform=tf_val)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OLSPLbfrZ5L"
   },
   "outputs": [],
   "source": [
    "print(train_dataset.classes)\n",
    "print(val_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SahkQIxjt58g"
   },
   "source": [
    "### データローダ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCR0mO3lrZ2n"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                        batch_size = 64, shuffle = True)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
    "                        batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxAtiw8TuCGS"
   },
   "source": [
    "## ■モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBBO8vlsrZ0I"
   },
   "outputs": [],
   "source": [
    "# モデルDL\n",
    "net = models.vgg16(pretrained = True)\n",
    "\n",
    "# アーキ変更\n",
    "# 【変更前】(fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    "# 【変更後】(fc): Linear(in_features=512, out_features=3, bias=True)\n",
    "net.fc = nn.Linear(512, 3) # fc層を置き換える\n",
    "\n",
    "# 意図通りに変更できたかどうかを目視で確認\n",
    "for name, param in net.named_parameters():\n",
    "  print(f'name={name}, param={param.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klIN4JZusfsf"
   },
   "outputs": [],
   "source": [
    "# 指定層の重みを学習中に変更できるようにする。\n",
    "\n",
    "# 転移学習（出力層）\n",
    "update_param_names = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
    "\n",
    "# ファインチューニング（出力層以外）\n",
    "IS_ENABLE_FINETUNING = 0 # ファインチューニングしない場合は「0」\n",
    "update_param_names_fine = [\"features\",\"classifier.0.weight\",\"classifier.0.bias\",\"classifier.3.weight\",\"classifier.3.bias\"]\n",
    "\n",
    "if bool(IS_ENABLE_FINETUNING):\n",
    "  update_param_names = update_param_names_fine + update_param_names\n",
    "\n",
    "params_to_update = []\n",
    "for name, param in net.named_parameters():\n",
    "  if  \"features\" in name and \"features\" in update_param_names:\n",
    "    param.requires_grad = True\n",
    "    params_to_update.append(param)\n",
    "    print(f'{name} is tunable.')\n",
    "  elif name in update_param_names:\n",
    "    param.requires_grad = True\n",
    "    params_to_update.append(param)\n",
    "    print(f'{name} is tunable.')\n",
    "  else:\n",
    "    param.requires_grad = False # 指定外層の重みは学習で変更されないようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suCN1fkgsfqO"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)\n",
    "model = net.to(device)\n",
    "summary(model, input_size=(3,my_size, my_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNWGFZWGvJLr"
   },
   "source": [
    "## ■学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0OiPrEBJca6z"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sys.stdout = open('/content/drive/My Drive/tmp/result.txt', 'w')\n",
    "model.train() # 再学習モードに設定する\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 50\n",
    "running_loss_history = [] # 学習時の損失値の履歴\n",
    "running_corrects_history = [] # 学習時の正解率の履歴\n",
    "val_running_loss_history = [] # 評価時の損失値の履歴\n",
    "val_running_corrects_history = [] # 評価時の正解率の履歴\n",
    "\n",
    "for e in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  running_corrects = 0.0\n",
    "  val_running_loss = 0.0\n",
    "  val_running_corrects = 0.0\n",
    "  \n",
    "  for inputs, labels in train_dataloader:\n",
    "    model.train()\n",
    "    outputs = model(inputs.to(device))\n",
    "    loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    running_loss += loss.item()\n",
    "    running_corrects += torch.sum(preds == (labels.data).to(device))\n",
    "  \n",
    "  else:\n",
    "    with torch.no_grad():\n",
    "      model.eval()\n",
    "      true_label_per_epoch, pred_label_per_epoch = [],[]\n",
    "\n",
    "      for val_inputs, val_labels in val_dataloader:\n",
    "        val_outputs = model(val_inputs.to(device))\n",
    "        val_loss = criterion(val_outputs, val_labels.to(device))\n",
    "\n",
    "        _, val_preds = torch.max(val_outputs, 1)\n",
    "        val_running_loss += val_loss.item()\n",
    "        val_running_corrects += torch.sum(val_preds == (val_labels.data).to(device))\n",
    "\n",
    "        true_label_per_epoch += (val_labels.numpy()).tolist()\n",
    "        pred_label_per_epoch += (val_preds.to(\"cpu\").numpy()).tolist()\n",
    "\n",
    "#   学習過程を記録\n",
    "    epoch_loss = running_loss/len(train_dataloader.dataset)\n",
    "    epoch_acc = running_corrects.float()/ len(train_dataloader.dataset)\n",
    "    running_loss_history.append(epoch_loss)\n",
    "    running_corrects_history.append(epoch_acc)\n",
    "    \n",
    "    val_epoch_loss = val_running_loss/len(val_dataloader.dataset)\n",
    "    val_epoch_acc = val_running_corrects.float()/len(val_dataloader.dataset)\n",
    "    val_running_loss_history.append(val_epoch_loss)\n",
    "    val_running_corrects_history.append(val_epoch_acc)\n",
    "    \n",
    "    print('epoch *', (e+1))\n",
    "    print(f'training loss: {epoch_loss:.4f} (={running_loss:.2f}/{len(train_dataloader.dataset)}), \\\n",
    "    training acc {epoch_acc.item():.4f} (={running_corrects:.2f}/{len(train_dataloader.dataset)})')\n",
    "    print(f'validation loss: {val_epoch_loss:.4f} (={val_running_loss:.2f}/{len(val_dataloader.dataset)}), \\\n",
    "    validation acc {val_epoch_acc.item():.4f} (={val_running_corrects:.2f}/{len(val_dataloader.dataset)})') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xC7XXnGgI_RU"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout.close()\n",
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRm0e4BuhR07"
   },
   "source": [
    "## ■評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adp6Ihnwsflh"
   },
   "outputs": [],
   "source": [
    "# 学習精度曲線（青）、テスト精度曲線（橙）\n",
    "plt.plot(running_corrects_history, label='training accuracy')\n",
    "plt.plot(val_running_corrects_history, label='validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FuK4iHjI-SC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sb4lA0gNsfjD"
   },
   "outputs": [],
   "source": [
    "# ロス（誤差）関数曲線\n",
    "plt.plot(running_loss_history, label='training loss')\n",
    "plt.plot(val_running_loss_history, label='validation loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torch_vgg16_cat_dog.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
